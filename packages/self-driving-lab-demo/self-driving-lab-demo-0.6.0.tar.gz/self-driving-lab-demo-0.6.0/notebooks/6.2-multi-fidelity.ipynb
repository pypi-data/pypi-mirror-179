{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sparks-baird/self-driving-lab-demo/blob/main/notebooks/6.2-multi-fidelity.ipynb)\n",
    "# Multi-fidelity Optimization (Introduction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous notebook, we covered multi-objective optimization: i.e. looking at\n",
    "optimal tradeoffs between multiple, sometimes competing, objectives. Here, we'll take a\n",
    "look a multi-fidelity optimization. First, let's start off by loosely defining a\n",
    "fidelity parameter as a parameter that controls the quality of the information being\n",
    "obtained. For example, in a finite element modeling simulation, a coarse grid spacing\n",
    "might result in a large amount of noise or bias. We refer to this as low-fidelity.\n",
    "Likewise, a finer grid spacing will likely result in much less noise - hence,\n",
    "high-fidelity. Situations such as these are typically referred to as continuous fidelity\n",
    "parameters.\n",
    "\n",
    "Similarly, there exists discrete, categorical fidelity parameters. For example, a thorough\n",
    "experiment performed in a wetlab is considered higher-fidelity than a corresponding\n",
    "simulation because the experiment by definition is meant to be more representative of\n",
    "reality. The phrase \"experimental validation\" comes to mind in this context. Likewise,\n",
    "we could have multiple types of instruments that measure the same property, but at\n",
    "different resolutions and therefore at different fidelities. Multi-fidelity optimization\n",
    "should be used when increasing/decreasing a parameter is known to result in more\n",
    "trustworthy data. See also [discussion about multi-task vs. multi-fidelity optimization](https://github.com/facebook/Ax/issues/1038).\n",
    "\n",
    "For the demo, we have two notions of fidelity parameters that we can explore:\n",
    "- Integration time as an analytic function of `atime` and `astep`, where longer\n",
    "  integration times result in less noise, and thus higher fidelity (continuous fidelity\n",
    "  parameter, though technically discrete since there are a limited number of choices)\n",
    "- Simulated spectrum vs. experimental spectrum (discrete, categorical fidelity parameter)\n",
    "\n",
    "We'll explore both in the following two notebooks. We will limit ourselves to single-objective\n",
    "optimization; however, I plan to cover scenarios that incorporate multiple advanced\n",
    "topics in a single optimization task: multi-objective, multi-fidelity, high-dimensional,\n",
    "constrained, and asynchronous or batch optimization. Stay tuned!\n",
    "\n",
    "Continous multi-fidelity: [![Open In\n",
    "Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sparks-baird/self-driving-lab-demo/blob/main/notebooks/6.2.1-multi-fidelity-continuous.ipynb) [[GitHub](https://github.com/sparks-baird/self-driving-lab-demo/blob/main/notebooks/6.2.1-multi-fidelity-continous.ipynb)]\n",
    "\n",
    "Discrete multi-fidelity: [![Open In\n",
    "Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sparks-baird/self-driving-lab-demo/blob/main/notebooks/6.2.2-multi-fidelity-discrete.ipynb) [[GitHub](https://github.com/sparks-baird/self-driving-lab-demo/blob/main/notebooks/6.2.2-multi-fidelity-discrete.ipynb)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('sdl-demo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "70cb6d4911b67e25d1487ebd620c5d1370239efaaf47f3851af44f5c5a26f988"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
