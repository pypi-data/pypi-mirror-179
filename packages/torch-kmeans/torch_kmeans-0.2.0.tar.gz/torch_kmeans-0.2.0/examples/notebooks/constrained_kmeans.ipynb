{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Constrained KMeans Examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install torch-kmeans"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.datasets import make_blobs\n",
    "from torch_kmeans import ConstrainedKMeans\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# function to generate some clustering data\n",
    "def get_data(bs: int = 1,\n",
    "             n: int = 20,\n",
    "             d: int = 2,\n",
    "             k: int = 4,\n",
    "             different_k: bool = False,\n",
    "             k_lims = (2, 5),\n",
    "             add_noise: bool = True,\n",
    "             fp_dtype = torch.float32,\n",
    "             seed: int = 42):\n",
    "    torch.manual_seed(seed)\n",
    "    if different_k:\n",
    "        a, b = k_lims\n",
    "        k = torch.randint(low=a, high=b, size=(bs,)).long()\n",
    "    else:\n",
    "        k = torch.empty(bs).fill_(k).long()\n",
    "\n",
    "    # generate pseudo clustering data\n",
    "    x, y = [], []\n",
    "    for i, k_ in enumerate(k.numpy()):\n",
    "        x_, y_ = make_blobs(n_samples=n, centers=k_, n_features=d, random_state=seed+i)\n",
    "        x.append(x_)\n",
    "        y.append(y_)\n",
    "    x = torch.from_numpy(np.stack(x, axis=0))\n",
    "    y = torch.from_numpy(np.stack(y, axis=0))\n",
    "    if add_noise:\n",
    "        x += torch.randn(x.size())\n",
    "\n",
    "    return x.to(fp_dtype), y, k\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# create some data (BS, N, D)\n",
    "# i.e. 1 instance with N=20 points and D=2 features\n",
    "BS = 1\n",
    "K = 4\n",
    "x, y, k_per_instance = get_data(bs=BS, n=20, d=2, k=K, different_k=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To solve a constrained clustering problem, we need to assign some weights to the given samples.\n",
    "The simplest constrained clustering task is arguably the case where each cluster has\n",
    "a maximum number of points it can accommodate."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
      "         0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
      "         0.2000, 0.2000]])\n"
     ]
    }
   ],
   "source": [
    "# to simulate this case we simply generate weights of 1 for all samples.\n",
    "# Since the algorithm expects normalized weights between 0 and 1\n",
    "# we normalize them by the max number of points per cluster\n",
    "MAX_POINTS = 5\n",
    "w = torch.ones(x.shape[:-1])\n",
    "w /= MAX_POINTS\n",
    "print(w)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full batch converged at iteration 6/100 with center shifts: \n",
      "tensor([0.]).\n",
      "tensor([[0, 0, 3, 0, 1, 2, 0, 1, 3, 1, 2, 3, 2, 3, 2, 0, 2, 1, 3, 1]])\n",
      "tensor([5, 5, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "# weights need to be explicitly provided\n",
    "model = ConstrainedKMeans()\n",
    "result = model(x, k=K, weights=w)\n",
    "print(result.labels)\n",
    "# check if constraint is valid\n",
    "_, cnts = torch.unique(result.labels, return_counts=True)\n",
    "print(cnts)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "BS = 1\n",
    "K = 4\n",
    "x, y, k_per_instance = get_data(bs=BS, n=22, d=2, k=K, different_k=False)\n",
    "\n",
    "# More complex constrained clustering tasks come with different weights for different samples\n",
    "weights = torch.abs(torch.randn(size=y.size()))\n",
    "# normalize weights per cluster given by label\n",
    "norm_weights = torch.empty(y.size())\n",
    "for i in range(BS):\n",
    "    w = weights[i]\n",
    "    y_ = y[i]\n",
    "    unq = len(torch.unique(y_))\n",
    "    nw = torch.empty(y_.size())\n",
    "    for j in range(unq):\n",
    "        msk = y_ == j\n",
    "        w_ = w[msk]\n",
    "        nw[msk] = w_ / (w_.sum() * 1.15)\n",
    "    norm_weights[i] = nw\n",
    "assert (norm_weights.sum(dim=-1).long() <= k_per_instance).all()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full batch converged at iteration 5/100 with center shifts: \n",
      "tensor([0.]).\n",
      "tensor([[0, 0, 0, 0, 2, 3, 1, 2, 3, 0, 1, 3, 2, 1, 3, 1, 3, 1, 0, 2, 2, 1]])\n",
      "tensor([6, 6, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "model = ConstrainedKMeans()\n",
    "result = model(x, k=K, weights=norm_weights)\n",
    "print(result.labels)\n",
    "_, cnts = torch.unique(result.labels, return_counts=True)\n",
    "print(cnts)\n",
    "for i in range(K):\n",
    "    msk = y == i\n",
    "    w_sum = norm_weights[msk].sum()\n",
    "    assert w_sum <= 1\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
