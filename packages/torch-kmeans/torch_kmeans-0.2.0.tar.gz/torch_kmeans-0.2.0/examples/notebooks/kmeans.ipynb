{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Standard KMeans Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install torch-kmeans"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.datasets import make_blobs\n",
    "from torch_kmeans import KMeans\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# function to generate some clustering data\n",
    "def get_data(bs: int = 1,\n",
    "             n: int = 20,\n",
    "             d: int = 2,\n",
    "             k: int = 4,\n",
    "             different_k: bool = False,\n",
    "             k_lims = (2, 5),\n",
    "             add_noise: bool = True,\n",
    "             fp_dtype = torch.float32,\n",
    "             seed: int = 42):\n",
    "    torch.manual_seed(seed)\n",
    "    if different_k:\n",
    "        a, b = k_lims\n",
    "        k = torch.randint(low=a, high=b, size=(bs,)).long()\n",
    "    else:\n",
    "        k = torch.empty(bs).fill_(k).long()\n",
    "\n",
    "    # generate pseudo clustering data\n",
    "    x, y = [], []\n",
    "    for i, k_ in enumerate(k.numpy()):\n",
    "        x_, y_ = make_blobs(n_samples=n, centers=k_, n_features=d, random_state=seed+i)\n",
    "        x.append(x_)\n",
    "        y.append(y_)\n",
    "    x = torch.from_numpy(np.stack(x, axis=0))\n",
    "    y = torch.from_numpy(np.stack(y, axis=0))\n",
    "    if add_noise:\n",
    "        x += torch.randn(x.size())\n",
    "\n",
    "    return x.to(fp_dtype), y, k\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# create some data (BS, N, D)\n",
    "# i.e. 1 instance with N=20 points and D=2 features\n",
    "BS = 1\n",
    "K = 4\n",
    "x, _, _ = get_data(bs=BS, n=20, d=2, k=K, different_k=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The inputs to the algorithm must be torch Tensors,\n",
    "so if your input is e.g. a numpy array, simply use the torch from_numpy() converter\n",
    "to make it a Tensor:\n",
    "```python\n",
    "x_np = np.random.randn(1,2,3)\n",
    "x_pt = torch.from_numpy(x_np)\n",
    "```\n",
    "You can convert back the results again via 'tensor.numpy()'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMeans(init: 'rnd', num_init: 8, max_iter: 100, distance: LpDistance(), tolerance: 0.0001, normalize: None)\n"
     ]
    }
   ],
   "source": [
    "# initialize model\n",
    "model = KMeans(n_clusters=K)\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full batch converged at iteration 6/100 with center shifts = tensor([0.]).\n",
      "ClusterResult(labels=tensor([[2, 2, 3, 2, 1, 0, 2, 1, 3, 1, 0, 3, 0, 3, 0, 2, 0, 1, 3, 1]]), centers=tensor([[[-9.4776,  7.1169],\n",
      "         [-7.8595, -6.1823],\n",
      "         [-2.4830,  8.0605],\n",
      "         [ 5.6283,  1.2469]]]), inertia=tensor([59.8551]), x_org=tensor([[[ -1.0518,  11.0441],\n",
      "         [ -3.3334,   6.3465],\n",
      "         [  4.3055,   1.0529],\n",
      "         [ -2.3103,   5.4963],\n",
      "         [ -8.7828,  -4.8557],\n",
      "         [-10.5590,   6.1168],\n",
      "         [ -3.7005,   7.9891],\n",
      "         [ -7.6620,  -7.1754],\n",
      "         [  5.7378,   1.9245],\n",
      "         [ -7.9777,  -6.7322],\n",
      "         [ -9.3876,   6.4422],\n",
      "         [  6.9063,   3.4280],\n",
      "         [ -8.0649,   7.8160],\n",
      "         [  5.3055,  -0.2846],\n",
      "         [ -7.6417,   7.7096],\n",
      "         [ -2.0192,   9.4264],\n",
      "         [-11.7349,   7.4999],\n",
      "         [ -6.0072,  -5.8342],\n",
      "         [  5.8864,   0.1140],\n",
      "         [ -8.8677,  -6.3140]]]), x_norm=tensor([[[ -1.0518,  11.0441],\n",
      "         [ -3.3334,   6.3465],\n",
      "         [  4.3055,   1.0529],\n",
      "         [ -2.3103,   5.4963],\n",
      "         [ -8.7828,  -4.8557],\n",
      "         [-10.5590,   6.1168],\n",
      "         [ -3.7005,   7.9891],\n",
      "         [ -7.6620,  -7.1754],\n",
      "         [  5.7378,   1.9245],\n",
      "         [ -7.9777,  -6.7322],\n",
      "         [ -9.3876,   6.4422],\n",
      "         [  6.9063,   3.4280],\n",
      "         [ -8.0649,   7.8160],\n",
      "         [  5.3055,  -0.2846],\n",
      "         [ -7.6417,   7.7096],\n",
      "         [ -2.0192,   9.4264],\n",
      "         [-11.7349,   7.4999],\n",
      "         [ -6.0072,  -5.8342],\n",
      "         [  5.8864,   0.1140],\n",
      "         [ -8.8677,  -6.3140]]]), k=tensor([4]), soft_assignment=None)\n"
     ]
    }
   ],
   "source": [
    "# pytorch style call\n",
    "result = model(x)\n",
    "print(result)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "the returned result tuple has many different attributes\n",
    "associated with the input and the clustering result:\n",
    "\n",
    "ClusterResult:\n",
    "\n",
    "\"Named and typed result tuple for kmeans algorithms\"\n",
    "\n",
    "- labels: label for each sample in x\n",
    "- centers: corresponding coordinates of cluster centers\n",
    "- inertia: sum of squared distances of samples to their closest cluster center\n",
    "- x_org: original x\n",
    "- x_norm: normalized x which was used for cluster centers and labels\n",
    "- k: number of clusters\n",
    "- soft_assignment: assignment probabilities of soft kmeans\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full batch converged at iteration 6/100 with center shifts = tensor([0.]).\n",
      "True\n",
      "tensor([[2, 2, 3, 2, 1, 0, 2, 1, 3, 1, 0, 3, 0, 3, 0, 2, 0, 1, 3, 1]])\n"
     ]
    }
   ],
   "source": [
    "# Instead we can also use scikit-learn style calls:\n",
    "model = KMeans(n_clusters=K)\n",
    "fitted_model = model.fit(x)\n",
    "print(fitted_model.is_fitted)\n",
    "labels = fitted_model.predict(x)\n",
    "print(labels)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full batch converged at iteration 6/100 with center shifts = tensor([0.]).\n",
      "tensor([[2, 2, 3, 2, 1, 0, 2, 1, 3, 1, 0, 3, 0, 3, 0, 2, 0, 1, 3, 1]])\n"
     ]
    }
   ],
   "source": [
    "# or directly\n",
    "labels = KMeans(n_clusters=K).fit_predict(x)\n",
    "print(labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full batch converged at iteration 6/100 with center shifts = tensor([0.]).\n",
      "tensor([4])\n"
     ]
    }
   ],
   "source": [
    "# instead of at model initialization, we can also specify the number of clusters\n",
    "# directly in the forward pass\n",
    "\n",
    "model = KMeans()\n",
    "result = model(x, k=K)\n",
    "print(result.k)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full batch converged at iteration 7/100 with center shifts = tensor([0., 0., 0.]).\n",
      "tensor([4, 4, 4])\n",
      "tensor([[2, 2, 3, 2, 1, 0, 2, 1, 3, 1, 0, 3, 0, 3, 0, 2, 0, 1, 3, 1],\n",
      "        [2, 3, 1, 2, 2, 2, 3, 1, 1, 0, 0, 1, 0, 0, 3, 1, 3, 0, 3, 2],\n",
      "        [3, 2, 0, 3, 3, 1, 0, 2, 1, 1, 1, 2, 0, 3, 2, 1, 0, 2, 3, 0]])\n"
     ]
    }
   ],
   "source": [
    "# the algorithm works for mini-batches of instances\n",
    "# here we create a batch of 3 instances with N=20 points and D=2 features\n",
    "BS = 3\n",
    "K = 4\n",
    "x, _, _ = get_data(bs=BS, n=20, d=2, k=K, different_k=False)\n",
    "\n",
    "model = KMeans()\n",
    "result = model(x, k=K)\n",
    "print(result.k)\n",
    "print(result.labels)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 4, 3])\n",
      "Full batch converged at iteration 7/100 with center shifts = tensor([0., 0., 0.]).\n",
      "tensor([2, 4, 3])\n",
      "tensor([[0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1],\n",
      "        [2, 3, 1, 2, 2, 2, 3, 1, 1, 0, 0, 1, 0, 0, 3, 1, 3, 0, 3, 2],\n",
      "        [0, 0, 2, 1, 0, 1, 1, 2, 0, 2, 1, 1, 1, 0, 2, 2, 2, 0, 0, 1]])\n"
     ]
    }
   ],
   "source": [
    "# we can also provide different numbers of clusters per instance\n",
    "BS = 3\n",
    "K = 4\n",
    "x, _, k_per_instance = get_data(bs=BS, n=20, d=2, k=K, different_k=True)\n",
    "\n",
    "# in case of different clusters we need to provide a Tensor\n",
    "# holding the number of clusters per instance\n",
    "print(k_per_instance)\n",
    "\n",
    "model = KMeans()\n",
    "result = model(x, k=k_per_instance)\n",
    "print(result.k)\n",
    "print(result.labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "if we have a good prior idea of where the cluster centers should be located,\n",
    "e.g. based on domain knowledge, we can provide these centers to the algorithm\n",
    "to speed up convergence and possibly improve the final quality of the clustering assignment"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-2.5329,  8.0106],\n",
      "         [ 6.1546,  1.7733],\n",
      "         [-7.8680, -6.1908],\n",
      "         [-8.7486,  7.8460]]])\n",
      "Full batch converged at iteration 2/100 with center shifts = tensor([0.]).\n",
      "tensor([[[-2.4830,  8.0605],\n",
      "         [ 5.6283,  1.2469],\n",
      "         [-7.8595, -6.1823],\n",
      "         [-9.4776,  7.1169]]])\n"
     ]
    }
   ],
   "source": [
    "BS = 1\n",
    "K = 4\n",
    "x, y, k_per_instance = get_data(bs=BS, n=20, d=2, k=K, different_k=False)\n",
    "# here we just use the ground truth labels from the generator\n",
    "# to set the centers to the group mean + a bit of noise\n",
    "centers = []\n",
    "for i in range(K):\n",
    "    msk = y == i\n",
    "    centers.append(x[msk].mean(dim=0) + torch.randn(1))\n",
    "centers = torch.stack(centers).unsqueeze(0) # add batch dimension\n",
    "print(centers)\n",
    "# initialize only one run, since we only provide one set of centers\n",
    "# (otherwise a warning will be raised)\n",
    "model = KMeans(num_init=1)\n",
    "result = model(x, k=K, centers=centers)\n",
    "print(result.centers)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "One nice feature of torch_kmeans is the possibility to leverage huge\n",
    "parallelism via execution on GPU.\n",
    "(On Colab you need to change the runtime type to 'GPU')\n",
    "\n",
    "To use the GPU if it is available, simply transfer your inputs to the GPU device\n",
    "and the model will automatically execute the algorithm on GPU.\n",
    "In order to keep thins simple and easy to maintain, torch_kmeans does not use a dedicated\n",
    "custom GPU kernel for kmeans but simply leverages the torch tensor operators on GPU\n",
    "for the most expensive computation steps.\n",
    "(Most of these steps are JIT compiled via torch.script as well)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True cuda:0\n",
      "Full batch converged at iteration 4/100 with center shifts = tensor([0.], device='cuda:0').\n",
      "True cuda:0\n",
      "False cpu\n"
     ]
    }
   ],
   "source": [
    "assert torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "x_cuda = x.to(device=device)\n",
    "print(x_cuda.is_cuda, x_cuda.device)\n",
    "\n",
    "model = KMeans()\n",
    "result = model(x_cuda, k=K)\n",
    "# be careful if you use the tensors of the result object\n",
    "# since now they are located on the GPU:\n",
    "lbl = result.labels\n",
    "print(lbl.is_cuda, lbl.device)\n",
    "# to transfer them back, just use '.cpu()'\n",
    "lbl = lbl.cpu()\n",
    "print(lbl.is_cuda, lbl.device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The massive parallelization can for example also be used to very efficiently\n",
    "find the best number of clusters for a given dataset by computing KMeans for\n",
    "different numbers of clusters k all in parallel and using the 'Elbow method'\n",
    "([https://en.wikipedia.org/wiki/Elbow_method_(clustering)](https://en.wikipedia.org/wiki/Elbow_method_(clustering))).\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full batch converged at iteration 8/100 with center shifts = tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0').\n",
      "k=2: 1549.114990234375\n",
      "k=3: 426.5956726074219\n",
      "k=4: 188.72926330566406\n",
      "k=5: 144.96826171875\n",
      "k=6: 116.29396057128906\n",
      "k=7: 101.1533203125\n",
      "k=8: 85.8719482421875\n",
      "k=9: 73.476318359375\n"
     ]
    }
   ],
   "source": [
    "BS = 1\n",
    "K = 6\n",
    "x, _, _ = get_data(bs=BS, n=50, d=2, k=6, different_k=False)\n",
    "\n",
    "assert torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "# replicate instances of x\n",
    "n_tries = 8\n",
    "x = x.expand(n_tries, 50, 2)\n",
    "x_cuda = x.to(device=device)\n",
    "# use different k between 2 and 10\n",
    "k_per_isntance = torch.arange(start=2, end=10).to(device=device)\n",
    "\n",
    "model = KMeans()\n",
    "result = model(x_cuda, k=k_per_isntance)\n",
    "# find k according to 'elbow method'\n",
    "for k, inrt in zip(k_per_isntance, result.inertia.cpu()):\n",
    "    print(f\"k={k}: {inrt}\")\n",
    "# the decrease in inertia after k=6 is much smaller than for the prior steps,\n",
    "# forming the characteristic 'elbow'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
