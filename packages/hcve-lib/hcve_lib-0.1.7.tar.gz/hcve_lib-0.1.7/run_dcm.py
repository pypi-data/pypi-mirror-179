from typing import Dict, Tuple

from optuna import Trial
from pandas import DataFrame

from deps.common import get_variables_cached
from deps.custom_types import MethodDefinition
from deps.logger import logger
from hcve_lib.cv import cross_validate
from hcve_lib.cv import predict_survival, CROSS_VALIDATE_KEY
from hcve_lib.data import to_survival_y_records
from hcve_lib.pipelines import TransformTarget
from pipelines import get_standard_pipeline
from run_lco_nested_optimization import get_lco_cv
from dcm import dcm_tf as dcm

data, metadata, X, y = get_variables_cached()
n = len(X)

tr_size = int(n * 0.70)
vl_size = int(n * 0.10)
te_size = int(n * 0.20)

X = X.to_numpy()
t = y['data']['tte'].to_numpy()
e = y['data']['label'].to_numpy()

X_train, X_test, X_val = X[:tr_size], X[-te_size:], X[tr_size:tr_size +
                                                      vl_size]
t_train, t_test, t_val = t[:tr_size], t[-te_size:], t[tr_size:tr_size +
                                                      vl_size]
e_train, e_test, e_val = e[:tr_size], e[-te_size:], e[tr_size:tr_size +
                                                      vl_size]

k = 3
h = 100

model = dcm.DeepCoxMixture(k, h)

# We `train` the model for 50 epochs,
# with a learning rate of 1e-3,
# a batch size of 128 using the Adam optimizer.
model, losses = dcm.train(model,
                          X_train,
                          t_train,
                          e_train,
                          X_val,
                          t_val,
                          e_val,
                          epochs=50,
                          lr=1e-3,
                          bs=128,
                          use_posteriors=False,
                          random_state=0,
                          return_losses=True,
                          patience=3)

# class DeepCoXMiXtureAdapter(DeepCoXMiXtures):
#     def fit(self, X, y, **kwargs):
#         super().fit(
#             X.to_numpy(),
#             y['data']['tte'].to_numpy(),
#             y['data']['label'].to_numpy(),
#         )
#         return self
#
#     def predict(self, X, **kwargs):
#         return super().predict_mean(X)
#
#
# class DeepCoXMiXture(MethodDefinition):
#     @staticmethod
#     def get_estimator(X: DataFrame, verbose=True, advanced_impute=False):
#         return get_standard_pipeline(
#             DeepCoXMiXtureAdapter(),
#             X,
#             advanced_impute=advanced_impute,
#         )
#
#     @staticmethod
#     def optuna(trial: Trial) -> Tuple[Trial, Dict]:
#         hyperparameters = {
#             CROSS_VALIDATE_KEY: {
#                 'missing_fraction':
#                 trial.suggest_uniform(
#                     f'{CROSS_VALIDATE_KEY}__missing_fraction', 0.1, 1),
#             },
#             'estimator__inner': {
#                 'l1_ratio':
#                 1 - trial.suggest_loguniform('estimator_n_alphas', 0.1, 1),
#             }
#         }
#         return trial, hyperparameters
#
#     process_y = to_survival_y_records
#     predict = predict_survival
#
#
# data, metadata, X, y = get_variables_cached()
# splits = get_lco_cv(X, y, data)
# result = cross_validate(
#     X,
#     y,
#     DeepCoXMiXture.get_estimator,
#     DeepCoXMiXture.predict,
#     splits,
#     n_jobs=1,
#     logger=logger,
# )
# # model = ()
# # model.fit()
# # model.predict_risk()
