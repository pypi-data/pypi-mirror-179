{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Download configuration from huggingface.co and cache.\n",
    "model_name = \"gpt2\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50256"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.unk_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"Hi, what is your name?\\n\\nI'm a student at the University of California, Berkeley. I'm a student at the University of California, Berkeley. I'm a student at the University of California, Berkeley. I'm a student at the University of California, Berkeley. I'm a student at the University of California, Berkeley. I'm a student at the University of California, Berkeley. I'm a student at the University of California, Berkeley. I'm a student at the University\",\n",
       " 'My name is John.The name is John.The name is John.The name is John.The name is John.The name is John.The name is John.The name is John.The name is John.The name is John.The name is John.The name is John.The name is John.The name is John.The name is John.The name is John.The name is John.The name is John.The name is John.The name is']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "text = tokenizer.batch_encode_plus(\n",
    "    [\"Hi, what is your name?\", \"My name is John.\"], \n",
    "    return_tensors=\"pt\", \n",
    "    add_special_tokens=True,\n",
    "    padding=True,\n",
    ")\n",
    "# text = {'input_ids': torch.tensor([[2061,  318,  534, 1438,   30]]), 'attention_mask': torch.tensor([[1, 1, 1, 1, 1]])}\n",
    "# text['input_ids'] = tensor([[   0, 2264,   16,  110,  766,  116 ]])\n",
    "# text['attention_mask'] = tensor([[1, 1, 1, 1, 1, 1]])\n",
    "\n",
    "generated_tokens = model.generate(\n",
    "\t**text,\n",
    "\tmax_length=100,\n",
    ")\n",
    "input_shape = text['input_ids'].shape\n",
    "# tokenizer.decode(generated_tokens[0], skip_special_tokens=False)\n",
    "tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[792,   6,  44,  24,  66, 193,  20],\n",
       "        [ 42, 193,  24, 356,   3,   3,   3]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = text['input_ids'].shape\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 8718,  1197,  1197,  1197,  2275,  1197,  1197, 13063,  1197, 13063,\n",
       "        13063,  2275, 13063, 13063, 13063,  8201, 13063, 13063,  5995, 13063,\n",
       "        13063,  2229, 13063, 13063,  4248, 13063, 13063,  1197,  5995, 13063,\n",
       "         2229,  5995, 13063,  5995,  2229, 13063,  2229,  2229, 13063,  5995,\n",
       "         5995, 13063,     3, 13063, 13063,   222, 13063, 13063,  2496, 13063,\n",
       "        13063,  4032, 13063, 13063,     3,  2229,  2229,  5995,  2229,  2229,\n",
       "         2229,     3, 13063,  2229,  2496, 13063,  2229,     3,  2229, 13063,\n",
       "         2496,  2229,  2229,  2496,  2229, 13063,  4032,  2229,  2229,  2275,\n",
       "        13063,  2229,   222,  2229,  2229,  4032,  2229, 13063,     3,  5995,\n",
       "         2229,  5995,     2])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_tokens[0][input_shape[1]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' world'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"hello world\"[len(\"hello\"):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([\"hello what are doing today ?\", \"i am good , i just got off work and tired , i have two jobs .\", \"i just got done watching a horror movie\", \"i rather read , i've read about 20 books this year .\", \"wow ! i do love a good horror movie . loving this cooler weather\", \"but a good movie is always good .\", \"yes ! my son is in junior high and i just started letting him watch them too\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello what are doing today ?', 'i am good , i just got off work and tired , i have two jobs .', 'i just got done watching a horror movie', \"i rather read , i've read about 20 books this year .\", 'wow ! i do love a good horror movie . loving this cooler weather', 'but a good movie is always good .', 'yes ! my son is in junior high and i just started letting him watch them too']\n"
     ]
    }
   ],
   "source": [
    "print([\"hello what are doing today ?\", \"i am good , i just got off work and tired , i have two jobs .\", \"i just got done watching a horror movie\", \"i rather read , i've read about 20 books this year .\", \"wow ! i do love a good horror movie . loving this cooler weather\", \"but a good movie is always good .\", \"yes ! my son is in junior high and i just started letting him watch them too\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([\"hello what are doing today ?\", \"i am good , i just got off work and tired , i have two jobs .\", \"i just got done watching a horror movie\", \"i rather read , i've read about 20 books this year .\", \"wow ! i do love a good horror movie . loving this cooler weather\", \"but a good movie is always good .\", \"yes ! my son is in junior high and i just started letting him watch them too\", \"i work in the movies as well .\", \"neat ! ! i used to work in the human services field\", \"yes it is neat , i stunt double , it is so much fun and hard work .\", \"yes i bet you can get hurt . my wife works and i stay at home\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequence = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sequence[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 4, 5, 6, 7, 8, 9, 10]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sequence[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis 2, проверяю длину входных последовательностей среди всех моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "causal_models_list = [\n",
    "\t\"gpt2\",\n",
    "\t\"microsoft/DialoGPT-medium\",\n",
    "\t\"RUCAIBox/mvp\",\n",
    "\t\"roberta-base\",\n",
    "\t\"facebook/blenderbot_small-90M\",\n",
    "\t\"facebook/bart-base\",\n",
    "\t\"google/bigbird-pegasus-large-arxiv\",\n",
    "\t\"facebook/blenderbot-400M-distill\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dimweb/Desktop/deeppavlov/d_env/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"gpt2\",\n",
    ")\n",
    "\n",
    "tokens = [\n",
    "\t\"<с_sep>\",\n",
    "\t\"<p_sep>\",\n",
    "\t\"<chat>\",\n",
    "\t\"<persona>\",\n",
    "]\n",
    "\n",
    "tokenizer.add_tokens(tokens, special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpt2'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.init_kwargs['name_or_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_tokenizer': <tokenizers.Tokenizer at 0x562f4da79140>,\n",
       " '_decode_use_source_tokenizer': False,\n",
       " 'init_inputs': (),\n",
       " 'init_kwargs': {'unk_token': '<|endoftext|>',\n",
       "  'bos_token': '<|endoftext|>',\n",
       "  'eos_token': '<|endoftext|>',\n",
       "  'add_prefix_space': False,\n",
       "  'model_max_length': 1024,\n",
       "  'special_tokens_map_file': None,\n",
       "  'name_or_path': 'gpt2'},\n",
       " 'name_or_path': 'gpt2',\n",
       " '_processor_class': None,\n",
       " 'model_max_length': 1024,\n",
       " 'padding_side': 'right',\n",
       " 'truncation_side': 'right',\n",
       " 'model_input_names': ['input_ids', 'attention_mask'],\n",
       " 'deprecation_warnings': {},\n",
       " '_bos_token': '<|endoftext|>',\n",
       " '_eos_token': '<|endoftext|>',\n",
       " '_unk_token': '<|endoftext|>',\n",
       " '_sep_token': None,\n",
       " '_pad_token': None,\n",
       " '_cls_token': None,\n",
       " '_mask_token': None,\n",
       " '_pad_token_type_id': 0,\n",
       " '_additional_special_tokens': [],\n",
       " 'verbose': True,\n",
       " 'add_prefix_space': False}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[50258, 50257, 50259, 50260]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "special_tokens = tokenizer.convert_tokens_to_ids(tokens)\n",
    "special_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<с_sep><p_sep><chat><persona>'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(special_tokens, skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(special_tokens, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"<persona>Hello, how are you?<p_sep> persona_fact[1] <p_sep> persona_fact[2] <p_sep> persona_fact[3] <p_sep> persona_fact[4] <p_sep> <chat> реплика[-6] <с_sep> реплика[-5] <с_sep> реплика[-4] <с_sep> реплика[-3] <с_sep> реплика[-2] <с_sep> реплика[-1] <с_sep>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello, how are you? persona_fact[1]  persona_fact[2]  persona_fact[3]  persona_fact[4]   реплика[-6]  реплика[-5]  реплика[-4]  реплика[-3]  реплика[-2]  реплика[-1] '"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer(input_text)['input_ids'], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dimweb_persona_bot.dataloaders.persona_chat_dataloaders import PersonaChatDatasetV2\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "train_dataset = PersonaChatDatasetV2(\n",
    "    input_dataset_path=\"./datasets/persona_chat/train.json\",\n",
    ")\n",
    "\n",
    "valid_dataset = PersonaChatDatasetV2(\n",
    "    input_dataset_path=\"./datasets/persona_chat/valid.json\",\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"gpt2\",\n",
    ")\n",
    "\n",
    "tokens = [\n",
    "\t\"<с_sep>\",\n",
    "\t\"<p_sep>\",\n",
    "\t\"<chat>\",\n",
    "\t\"<persona>\",\n",
    "]\n",
    "\n",
    "tokenizer.add_tokens(tokens, special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'persona': ['i like to remodel homes .',\n",
       "  'i like to go hunting .',\n",
       "  'i like to shoot a bow .',\n",
       "  'my favorite holiday is halloween .'],\n",
       " 'history': [\"hi , how are you doing ? i'm getting ready to do some cheetah chasing to stay in shape .\",\n",
       "  'you must be very fast . hunting is one of my favorite hobbies .',\n",
       "  'i am ! for my hobby i like to do canning or some whittling .',\n",
       "  'i also remodel homes when i am not out bow hunting .',\n",
       "  \"that's neat . when i was in high school i placed 6th in 100m dash !\",\n",
       "  \"that's awesome . do you have a favorite season or time of year ?\",\n",
       "  'i do not . but i do have a favorite meat since that is all i eat exclusively .',\n",
       "  'what is your favorite meat to eat ?',\n",
       "  'i would have to say its prime rib . do you have any favorite foods ?',\n",
       "  'i like chicken or macaroni and cheese .',\n",
       "  'do you have anything planned for today ? i think i am going to do some canning .',\n",
       "  'i am going to watch football . what are you canning ?'],\n",
       " 'sample_id': '0_6'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_dataset[0]['history']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "def visualize_hist(x: np.ndarray, title: str):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.hist(x,linewidth=0.5, edgecolor=\"white\", bins=300)\n",
    "    plt.gca().set(title=title, ylabel='Frequency')\n",
    "    plt.show()\n",
    "    \n",
    "def show_lengths_hist(\n",
    "    dataset: PersonaChatDatasetV2, \n",
    "    field: str, \n",
    "    stage: str,\n",
    "    tokenizer: AutoTokenizer,\n",
    "):\n",
    "    lengths = []\n",
    "    items_set = set()\n",
    "    for i in range(len(dataset)):\n",
    "        sample = dataset[i]\n",
    "        for item in sample[field]:\n",
    "            items_set.add(item)\n",
    "            \n",
    "    items_set = list(items_set)\n",
    "    for item in items_set:\n",
    "        tokens = tokenizer.encode(item, add_special_tokens=False)\n",
    "        tokens_len = len(tokens)\n",
    "        lengths.append(tokens_len)\n",
    "    \n",
    "    model_name = tokenizer.init_kwargs['name_or_path']\n",
    "    title = f\"{stage} {field} {model_name}\"\n",
    "    \n",
    "    visualize_hist(np.array(lengths), title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_items = [\n",
    "\t[train_dataset, \"persona\", \"train\", tokenizer],\n",
    "\t[train_dataset, \"history\", \"train\", tokenizer],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for item in count_items:\n",
    "#     show_lengths_hist(*item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dimweb/Desktop/deeppavlov/d_env/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from dimweb_persona_bot.eda.eda_scripts import TokensLengthAnalyzerV1\n",
    "\n",
    "dataset_analyzer = TokensLengthAnalyzerV1(\n",
    "    train_dataset_path=\"./datasets/persona_chat/train.json\",\n",
    "    valid_dataset_path=\"./datasets/persona_chat/valid.json\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_analyzer.analyze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_analyzer.show_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Field: persona, Stage: train\n",
    "# Average replica length: 14.25\n",
    "\n",
    "\n",
    "# Field: persona, Stage: valid\n",
    "# Average replica length: 13.25\n",
    "\n",
    "\n",
    "# Field: history, Stage: train\n",
    "# Average replica length: 19.75\n",
    "\n",
    "\n",
    "# Field: history, Stage: valid\n",
    "# Average replica length: 19.625\n",
    "\n",
    "\n",
    "# Field: persona\n",
    "# Field len percentile 50: 5.0\n",
    "# Field len percentile 95: 5.0\n",
    "# Field: history\n",
    "# Field len percentile 50: 12.0\n",
    "# Field len percentile 95: 14.0\n",
    "# Model: gpt2, Max length: 1024\n",
    "# Model: microsoft/DialoGPT-medium, Max length: 1024\n",
    "# Model: RUCAIBox/mvp, Max length: 1024\n",
    "# Model: roberta-base, Max length: 512\n",
    "# Model: facebook/blenderbot_small-90M, Max length: 512\n",
    "# Model: facebook/bart-base, Max length: 1024\n",
    "# Model: google/bigbird-pegasus-large-arxiv, Max length: 4096\n",
    "# Model: facebook/blenderbot-400M-distill, Max length: 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length persona: 70\n",
      "Max length history: 266\n",
      "Total max length: 359\n"
     ]
    }
   ],
   "source": [
    "max_length_persona = 5 * 14\n",
    "max_length_history = 14 * 19\n",
    "special_tokens_persona = 5 + 1\n",
    "special_tokens_history = 14 + 1\n",
    "special_tokens = 2\n",
    "print(f\"Max length persona: {max_length_persona}\")\n",
    "print(f\"Max length history: {max_length_history}\")\n",
    "print(f\"Total max length: {max_length_persona + max_length_history + special_tokens_persona + special_tokens_history + special_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.extend([1,2,3])\n",
    "test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('d_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c47eeeae5f0593d6ff7164e36f6d45daaa118b41372aa3e9757d1f066e1c76d7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
