# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/utils/experiment_utils.ipynb (unless otherwise specified).

__all__ = ['__author__', '__copyright__', '__license__', 'read_df', 'write_df', 'write_binary_df_if_not_exists',
           'get_experiment_data', 'get_parameters_columns', 'get_experiment_parameters', 'get_scores_columns',
           'get_experiment_scores', 'isnull', 'get_scores_names', 'get_monitored_training_metrics',
           'get_runs_with_results', 'get_parameters_unique', 'compact_parameters', 'replace_with_default_values',
           'remove_defaults', 'find_rows_with_parameters_dict', 'summarize_results', 'query', 'summary']

# Cell
__author__ = "Jaume Amores"
__copyright__ = "Copyright 2021, Johnson Controls"
__license__ = "MIT"

# Cell
import joblib
import pandas as pd
import numpy as np
import os
import sys
import time
from sklearn.model_selection import ParameterGrid
import warnings

from ..config import hp_defaults as dflt
from ..config.hpconfig import get_experiment_manager
warnings.filterwarnings('ignore')

# Cell
def read_df (path, name='experiments_data'):
    path_csv = f'{path}/{name}.csv'
    path_pickle = path_csv.replace('csv', 'pk')
    path_columns_pickle = path_csv.replace('.csv', '_columns.pk')
    experiment_data = None
    try:
        experiment_data = pd.read_pickle (path_pickle)
    except:
        try:
            experiment_data = pd.read_csv (path_csv, index_col=0)
            if os.path.exists (path_columns_pickle):
                c = joblib.load (path_columns_pickle)
                experiment_data.columns = pd.MultiIndex.from_tuples (c)
        except:
            experiment_data = None
    return experiment_data

# Cell
def write_df (df, path, name='experiments_data'):
    path_csv = f'{path}/{name}.csv'
    path_pickle = path_csv.replace('csv', 'pk')
    path_columns_pickle = path_csv.replace('.csv', '_columns.pk')
    df.to_pickle (path_pickle)
    df.to_csv (path_csv)
    c = df.columns.tolist ()
    joblib.dump (c, path_columns_pickle)

# Cell
def write_binary_df_if_not_exists (df, path, name='experiments_data'):
    path_pickle = f'{path}/{name}.pk'
    df.to_pickle (path_pickle)

# Cell
def get_experiment_data (experiments=None):
    """
    Returns data stored from previous experiments in the form DataFrame.

    If path_experiments is not given, it uses the default one.
    """
    from ..config.hpconfig import get_experiment_data
    return get_experiment_data (experiments=experiments)

# Cell
def get_parameters_columns (experiment_data, only_not_null=False):
    parameters = experiment_data[dflt.parameters_col].columns
    parameters = [(dflt.parameters_col, *x) for x in parameters]
    if only_not_null:
        parameters = np.array(parameters)[~experiment_data.loc[:,parameters].isnull().all(axis=0)].tolist()
        parameters = [(*x,) for x in parameters]
    return parameters

# Cell
def get_experiment_parameters (experiment_data, only_not_null=False):
    return experiment_data[get_parameters_columns (experiment_data, only_not_null=only_not_null)]

# Cell
def get_scores_columns (experiment_data=None, score_name=None, run_number=None):
    """
    Determine the columnns that provide evaluation scores.
    """
    if score_name is None and experiment_data is None:
        raise ValueError ('Either experiment_data or run_number should be different than None')
    if score_name is not None and not isinstance(score_name, list):
        score_name = [score_name]
    if run_number is not None and not isinstance(run_number, list):
        if isinstance(run_number, range): run_number=list(run_number)
        else: run_number = [run_number]
    if score_name is not None:
        scores_columns = []
        for score in score_name:
            new_columns = experiment_data[dflt.scores_col, score].columns
            if run_number is not None:
                new_columns = list(set(new_columns).intersection (run_number))
            new_columns = [(dflt.scores_col, score, c) for c in new_columns]
            scores_columns.extend (new_columns)
    else:
        scores_columns = experiment_data[dflt.scores_col].columns
        scores_columns = [(dflt.scores_col, *x) for x in scores_columns]
    return scores_columns

# Cell
def get_experiment_scores (experiment_data = None, score_name=None, run_number=None, remove_score_name=False):
    df = experiment_data[get_scores_columns (experiment_data, score_name=score_name, run_number=run_number)]
    if remove_score_name: df.columns = df.columns.get_level_values(2)
    return df

# Cell
def isnull (x): return x is None or np.isnan(x)

def get_scores_names (experiment_data=None, run_number=None, experiment=None, only_valid=True):
    """
    Determine the names of the scores included in experiment data.

    If run_number is provided, we provide the scores stored for that run number. If, in addition to this,
    experiment is provided, and only_valid=True, we provide only the scores that are not NaN for the given
    experiment number.
    """

    if run_number is None:
        scores_names = experiment_data[dflt.scores_col].columns.get_level_values(0).unique()
    else:
        if not isinstance(run_number, list):
            if isinstance(run_number, range): run_number=list(run_number)
            else: run_number = [run_number]
        scores_names = [(dflt.scores_col, *c) for c in experiment_data[dflt.scores_col].columns
                        if c[1] in run_number]
        if (experiment is not None) and only_valid:
            scores_names = [c for c in scores_names if not isnull(experiment_data.loc[experiment, c])]
        scores_names = pd.MultiIndex.from_tuples(scores_names).get_level_values(1).unique()
    scores_names = list(np.sort(scores_names))
    return scores_names

# Cell
def get_monitored_training_metrics (experiment, run_number=0, history_file_name='model_history.pk',
                                    path_results=None):
    if path_results is None:
        from ..config.hpconfig import get_path_results
        path_results = get_path_results(experiment, run_number)
    path_history = f'{path_results}/{history_file_name}'
    if os.path.exists(path_history):
        history=joblib.load(path_history)
        return list(history.keys())
    else:
        return []

# Cell
def get_runs_with_results (experiment_data = None, score_name=None, run_number=None):
    """
    Gets the list of run_number for whom there are results in experiment_data.
    """
    assert experiment_data is not None, 'experiment_data must be introduced'
    result_columns = get_scores_columns (experiment_data, score_name=score_name, run_number=run_number)
    completed_results = ~experiment_data.loc[:,result_columns].isnull()
    completed_results = completed_results.all(axis=0)
    completed_results = completed_results.iloc[np.where(completed_results)]
    completed_results = completed_results.index
    return completed_results.get_level_values(2).tolist()

# Cell
def get_parameters_unique(df):
    assert df.columns.nlevels == 3
    df_all = df
    df = df[dflt.parameters_col]
    if df.shape[0] > 1:
        parameters = []
        for k in df.columns:
            if len(df[k].unique()) > 1:
                parameters += [k]
    else:
        parameters = df.columns.tolist()
    df_parameters = df[parameters]
    columns = pd.MultiIndex.from_tuples([(dflt.parameters_col, *c) for c in parameters])
    df_parameters.columns = columns
    all_cols = df_all.columns.get_level_values(0).unique()
    no_par_cols = all_cols [all_cols != dflt.parameters_col]
    df_no_par = df_all[no_par_cols]
    df_all = pd.concat([df_parameters, df_no_par], axis=1)
    return columns, df_all

# Cell
def compact_parameters (df, number_characters=1):
    par_or = df.columns.get_level_values(1)
    par_new = [''.join(y[0].upper()+y[1:number_characters] for y in x.split('_')) for x in par_or]
    dict_rename = {k:v for k,v in zip(par_or, par_new)}
    if df.columns.nlevels==3:
        df.columns = pd.MultiIndex.from_arrays ([df.columns.get_level_values(0), par_new,
                                             df.columns.get_level_values(2)])
    else:
        df.columns = pd.MultiIndex.from_arrays ([df.columns.get_level_values(0), par_new])

    return df, dict_rename

# Cell
def replace_with_default_values (df, parameters={}):
    from ..config.hpconfig import get_default_parameters

    parameters_names = get_parameters_columns (df)

    for k in df.columns:
        experiments_idx=np.argwhere(df[k].isna().ravel()).ravel()
        experiments=df.index[experiments_idx]
        for experiment in experiments:
            parameters = df.loc[experiment, parameters_names].copy()
            parameters[parameters.isna().values] = None
            parameters = parameters.to_dict()
            parameters = {c[1]:parameters[c] for c in parameters if parameters[c] is not None}
            defaults = get_default_parameters(parameters)
            df.loc[experiment, k] = defaults.get(k[1])
    return df

# Cell
def remove_defaults (parameters):
    from ..config.hpconfig import get_default_parameters

    defaults = get_default_parameters(parameters)
    for key in defaults.keys():
        if key in parameters.keys() and (parameters[key] == defaults[key]):
            del parameters[key]
    return parameters

# Cell
def find_rows_with_parameters_dict (experiment_data, parameters_dict, create_if_not_exists=True,
                                    exact_match=True, ignore_keys=[], precision = 1e-10):
    """
    Finds rows that match parameters.

    If the dataframe doesn't have any parameter with that name, a new column
    is created and changed_dataframe is set to True.
    """
    changed_dataframe = False
    matching_all_condition = pd.Series([True]*experiment_data.shape[0])
    existing_keys = [par for par in parameters_dict.keys() if par not in ignore_keys]
    for parameter in existing_keys:
        mi_parameter = (dflt.parameters_col, parameter, '')
        if mi_parameter not in experiment_data.columns:
            if create_if_not_exists:
                experiment_data[mi_parameter] = None
                changed_dataframe = True
            else:
                raise ValueError ('parameter %s not found in experiment_data' %parameter)

        if experiment_data[mi_parameter].dtype == np.dtype('O'):
            idx_true = experiment_data[mi_parameter] == 'True'
            idx_false = experiment_data[mi_parameter] == 'False'
            experiment_data.loc[idx_true, mi_parameter]=True
            experiment_data.loc[idx_false, mi_parameter]=False
            try:
                experiment_data[mi_parameter] = pd.to_numeric(experiment_data[mi_parameter])
                experiment_data.loc[idx_true, mi_parameter]=True
                experiment_data.loc[idx_false, mi_parameter]=False
            except ValueError:
                pass
        if parameters_dict[parameter] is None:
            matching_condition = experiment_data[mi_parameter].isnull()
        elif experiment_data[mi_parameter].isnull().all():
            matching_condition = ~experiment_data[mi_parameter].isnull()
        elif ((type(parameters_dict[parameter]) == float) or
              (type(parameters_dict[parameter]) == np.float32) or
              (type(parameters_dict[parameter]) == np.float64)):
            if parameters_dict[parameter] == np.floor(parameters_dict[parameter]):
                matching_condition = experiment_data[mi_parameter]==parameters_dict[parameter]
            else:
                matching_condition = experiment_data[mi_parameter]==parameters_dict[parameter]
                for idx, v in enumerate(experiment_data[mi_parameter]):
                    if (type(v) == float or type(v) == np.float32 or type(v) == np.float64) and (np.abs(v-parameters_dict[parameter]) < precision):
                        matching_condition.iloc[idx]=True
                    else:
                        matching_condition.iloc[idx]=False
        else:
            matching_condition = experiment_data[mi_parameter]==parameters_dict[parameter]

        matching_all_condition = matching_all_condition & matching_condition.values

    if exact_match:
        rest_parameters = experiment_data[dflt.parameters_col].columns.get_level_values(0)
        rest_parameters = [par for par in rest_parameters if par not in parameters_dict.keys()]
        rest_parameters = [par for par in rest_parameters if par not in ignore_keys]
        for parameter in rest_parameters:
            mi_parameter = (dflt.parameters_col, parameter, '')
            matching_condition = experiment_data[mi_parameter].isnull()
            matching_all_condition = matching_all_condition & matching_condition.values

    matching_rows = matching_all_condition.index[matching_all_condition].tolist()

    return matching_rows, changed_dataframe, matching_all_condition

# Cell
def summarize_results(intersection=False,
                      experiments=None,
                      score_name=None,
                      min_results=0,
                      run_number=None,
                      parameters=None,
                      include_parameters=True,
                      include_num_results=True,
                      other_columns=None,
                      data=None,
                      ascending=False,
                      sort_key='mean',
                      #stats = ['mean','median','rank','min','max','std'],
                      stats=['mean','median','min','max','std']):
    """
    Obtains summary scores for the desired list of experiments.

    Uses the experiment_data csv for that purpose.
    """

    if data is None:
        experiment_data = get_experiment_data ()
        experiment_data_original = experiment_data.copy()
        if experiments is not None:
            experiment_data = experiment_data.loc[experiments,:]
        if parameters is not None:
            experiment_rows, _, _ = find_rows_with_parameters_dict (experiment_data, parameters,
                                                                    create_if_not_exists=False,
                                                                    exact_match=False)
            experiment_data = experiment_data.loc[experiment_rows]
    else:
        experiment_data = data.copy()

    if experiments is not None: experiment_data = experiment_data.loc[experiments]
    # Determine the columnns that provide evaluation scores.
    result_columns = get_scores_columns (experiment_data, score_name=score_name, run_number=run_number)

    # Determine num_results and select those with minimum number of runs
    #num_results = (~experiment_data.loc[:,result_columns].isnull()).sum(axis=1, level=1)
    num_results = (~experiment_data.loc[:,result_columns].isnull()).groupby(axis=1, level=1).sum()
    num_results.columns = pd.MultiIndex.from_product ([[dflt.stats_col], num_results.columns.tolist(),
                                                       ['num_results']])
    experiment_data = pd.concat([experiment_data, num_results], axis=1)
    num_results_columns = experiment_data.columns[
        experiment_data.columns.get_level_values(2) == 'num_results'
    ]
    min_num_results = experiment_data[num_results_columns].min(axis=1)
    experiment_data = experiment_data.drop (columns=num_results_columns)
    num_results_column = (dflt.num_results_col, 'num_results', '')
    experiment_data[num_results_column] = min_num_results
    if min_results > 0:
        number_before = experiment_data.shape[0]
        experiment_data = experiment_data[min_num_results>=min_results]
        print (f'{experiment_data.shape[0]} out of {number_before} experiments have {min_results} runs '
               'completed')

    # Take only those run_number where all experiments provide some score
    if intersection:
        number_before = len(result_columns)
        all_have_results = ~experiment_data.loc[:,result_columns].isnull().any(axis=0)
        result_columns = (np.array(result_columns)[all_have_results]).tolist()
        print (f'{len(result_columns)} out of {number_before} runs for whom all the '
                'selected experiments have completed')

    print (f'total data examined: {experiment_data.shape[0]} experiments '
           f'with at least {min_num_results.min()} runs done for each one')

    # TODO: make it work across different metrics
    #scores = experiment_data.loc[:, result_columns]
    #scores[scores.isna()]=np.nan
    #scores = -scores.values
    #rank = np.argsort(scores,axis=0)
    #rank = np.argsort(rank,axis=0).astype(np.float32)
    #rank[experiment_data.loc[:,result_columns].isnull()]=np.nan

    if other_columns != 'all':
        if include_parameters:
            columns_to_include = get_parameters_columns(experiment_data, True)
        else:
            columns_to_include = []
        if include_num_results:
            columns_to_include.append (num_results_column)
        if other_columns is not None:
            columns_to_include.extend(other_columns)
    else:
        columns_to_include = experiment_data.columns.tolist()
    scores_to_return={}
    stat_df_all = []
    stats_columns=[]
    for stat in stats:
        grouped_df = experiment_data.loc[:,result_columns].astype(float).groupby (level=1, axis=1)
        if stat=='argmax':
            stat_df = grouped_df.idxmax(axis=1).applymap (lambda x: x[2])
        elif stat=='argmin':
            stat_df = grouped_df.idxmin(axis=1).applymap (lambda x: x[2])
        else:
            stat_df = grouped_df.agg(stat)
        #stat_df = experiment_data.loc[:,result_columns].agg(stat, axis=1, level=1)
        stat_df.columns = pd.MultiIndex.from_product (
            [[dflt.stats_col], stat_df.columns.tolist(), [stat]])
        scores_to_return[stat] = stat_df.columns.tolist()
        stats_columns.extend (stat_df.columns.tolist())
        stat_df_all.append (stat_df)
    experiment_data = pd.concat ([experiment_data]+stat_df_all, axis=1)
    if score_name is None:
        score_name = experiment_data[dflt.scores_col].columns.get_level_values(0).unique()
        score_name = score_name[0]
    elif isinstance (score_name, list):
        score_name = score_name[0]
    summary = experiment_data.loc[:,columns_to_include+stats_columns]
    sort_column = None
    if sort_key is not None:
        if sort_key in stats:
            sort_column = (dflt.stats_col, score_name, sort_key)
        elif sort_key in summary[dflt.parameters_col].columns.get_level_values(0):
            sort_column = (dflt.parameters_col, sort_key, '')
        elif (dflt.scores_col in summary.columns.get_level_values(0) and
              sort_key in summary[dflt.scores_col].columns.get_level_values(0)):
            run_number = summary[dflt.scores_col].columns.get_level_values(1)[0]
            sort_column = (dflt.scores_col, sort_key, run_number)
    if sort_column is not None:
        summary = summary.sort_values(by=sort_column,ascending=ascending)
    summary = summary[summary.columns.sort_values()]

    return summary

# Cell
def query (path_experiments=None,
              folder_experiments=None,
              experiments=None,
              parameters_fixed={},
              parameters_variable={},
              parameters_all=[],
              exact_match=True,
              query_other_parameters=False,
              em=None,
              **kwargs):

    if em is None: em = get_experiment_manager ()
    if path_experiments is None: path_experiments = em.path_experiments

    if query_other_parameters:
        experiment_data = pd.read_csv(f'{path_experiments}/other_parameters.csv', index_col=0)
    else:
        experiment_data = em.get_experiment_data ()
    if experiment_data is None:
        return None

    non_valid_pars = set(
        [(dflt.parameters_col, c, '') for c in parameters_fixed.keys()]
    ).difference(set(experiment_data.columns))
    non_valid_pars = non_valid_pars.union(
        set([(dflt.parameters_col, c, '') for c in parameters_variable.keys()]
    ).difference(set(experiment_data.columns)))

    if len(non_valid_pars) > 0:
        print (f'\n**The following query parameters are not valid: {list(non_valid_pars)}**')
        print (f'\nValid parameters:\n{sorted(get_parameters_columns(experiment_data))}\n')

    parameters_multiple_values_all = list(ParameterGrid(parameters_variable))
    experiment_numbers = []
    for (i, parameters_multiple_values) in enumerate(parameters_multiple_values_all):
        parameters = parameters_multiple_values.copy()
        parameters.update(parameters_fixed)
        parameters_none = {k:v for k,v in parameters.items() if v is None}
        parameters_not_none = {k:v for k,v in parameters.items() if v is not None}

        parameters = remove_defaults (parameters_not_none)
        parameters.update(parameters_none)

        experiment_numbers_i, _, _ = find_rows_with_parameters_dict (experiment_data, parameters,
                                                                     ignore_keys=parameters_all,
                                                                     exact_match=exact_match)
        experiment_numbers += experiment_numbers_i

    experiment_data = experiment_data.iloc[experiment_numbers]

    if experiments is not None:
        experiment_data = experiment_data.loc[experiments]

    if query_other_parameters:
        return experiment_data

    summary = summarize_results (data=experiment_data, **kwargs)

    return summary

# Cell
def summary (df, experiments = None, score=None, compact=True):
    if experiments is not None:
        df = df.loc[experiments]
    if compact:
        _, df = get_parameters_unique(df)
    parameters_columns = get_parameters_columns(df, True)
    df_pars = df[parameters_columns]
    df_pars.columns = df_pars.columns.get_level_values(level=1)
    df_scores = get_experiment_scores (df, score_name=score, remove_score_name=True)
    df = pd.concat([df_pars, df_scores], axis=1)
    return df