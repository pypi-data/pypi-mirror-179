# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/00_tests/visualization/tst.experiment_visualization.ipynb (unless otherwise specified).

__all__ = ['generate_data_plot', 'test_plot_history', 'test_multiple_runs', 'test_plot_metric_relationship',
           'test_visualize_experiments']

# Cell
import pytest
import pandas as pd
import os
import joblib
from IPython.display import display
from dsblocks.utils.nbdev_utils import md

from hpsearch.visualization.experiment_visualization import *
from hpsearch.examples.dummy_experiment_manager import generate_data
from hpsearch.examples.dummy_experiment_manager import run_multiple_experiments
from hpsearch.visualization import plot_utils

# Comes from experiment_visualization.ipynb, cell
def generate_data_plot (folder):
    em = generate_data (folder)
    run_multiple_experiments (em=em, nruns=5, noise=0.1, rate=0.1, verbose=False)

    return em

# Comes from experiment_visualization.ipynb, cell
def test_plot_history ():
    em = generate_data_plot ('plot_history')

    md ('Plot all the metrics that have been stored in model_history')
    plot_multiple_histories ([8, 16], run_number=0, op='max', backend='matplotlib')

    md ('Plot only one metric, and three experiments')
    md ('We plot the test_accuracy metric')
    plot_multiple_histories ([8, 12, 16], run_number=0, op='max', metrics = 'test_accuracy',
                             backend='matplotlib')

    md ('Plot two metrics in same figure')
    plot_multiple_histories (experiments=[8], run_number=0, op='max', metrics = 'test_accuracy',
                             metrics_second = ['validation_accuracy'], backend='matplotlib')

    md ('Use plotly as backend')
    plot_multiple_histories ([8, 12, 16], run_number=0, op='max', metrics = 'test_accuracy',
                             backend='plotly')

    em.remove_previous_experiments (parent=True)

# Comes from experiment_visualization.ipynb, cell
def test_multiple_runs ():
    em = generate_data_plot ('multiple_runs')

    md ('#### calling plot_metric directly')
    multi_history_plotter = MultiHistoryPlotter (backend='matplotlib')
    traces, title, history = multi_history_plotter.plot_metric ('test_accuracy', 8, run_number=1);
    plot_utils.plot(title=title, xlabel='epoch', ylabel='test_accuracy', traces=traces,
                    backend='matplotlib');

    md ('#### calling obtain_average_history and plot_history')
    history = multi_history_plotter.obtain_average_history (['test_accuracy'], 8)
    traces, title = multi_history_plotter.plot_history (history, 'test_accuracy', run_number='mean',
                                                        traces=traces);
    plot_utils.plot(title=title, xlabel='epoch', ylabel='test_accuracy', traces=traces,
                    backend='matplotlib');

    md ('#### plotting multiple runs, and indicating a different path_experiments')
    import shutil
    shutil.move ('test_multiple_runs', 'test_another_location')
    multi_history_plotter = MultiHistoryPlotter (path_experiments='test_another_location/default',
                                                 backend='matplotlib')
    multi_history_plotter.plot_multiple_histories (experiments=[8], run_number=list(range(5))+['mean'],
                                                   metrics='test_accuracy')
    em.remove_previous_experiments (parent=True)

# Comes from experiment_visualization.ipynb, cell
def test_plot_metric_relationship ():
    em = generate_data_plot ('plot_metric_relationship')

    md ('plot relationship between validation and accuracy metrics')
    plot_metric_relationship ('validation_accuracy', 'test_accuracy', backend='plotly')

    md ('Highlight selected experiments')
    plot_metric_relationship ('validation_accuracy', 'test_accuracy', experiment_subset=[5,2], backend='plotly')

    em.remove_previous_experiments (parent=True)

# Comes from experiment_visualization.ipynb, cell
def test_visualize_experiments ():
    em = generate_data_plot ('visualize_experiments')

    visualize_experiments (visualization=['history', 'metric_correlation', 'custom'], experiments=[8,12, 16],
                       run_number=0, op='max', metrics = 'test_accuracy', backend='plotly',
                       metric_1='test_accuracy', metric_2='validation_accuracy')


    em.remove_previous_experiments (parent=True)