# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/utils/utils.ipynb.

# %% auto 0
__all__ = ['json_load', 'json_dump', 'make_reproducible', 'get_logging_level', 'delete_logger', 'set_logger', 'set_empty_logger',
           'set_verbosity', 'remove_previous_results', 'set_tf_loglevel', 'get_top_function', 'get_calling_modules',
           'add_commit_files', 'check_message', 'check_new_files', 'add_out_of_repo_files', 'compare_last_part',
           'check_last_part', 'get_action', 'get_norun', 'get_existing_kwargs', 'call_with_existing_kwargs',
           'save_config', 'argnames', 'store_attr', 'get_specific_dict_param', 'obtain_class_specific_attrs',
           'get_hierarchy_level', 'replace_attr_and_store']

# %% ../../nbs/utils/utils.ipynb 3
__author__ = "Jaume Amores"
__copyright__ = "Copyright 2021, Johnson Controls"
__license__ = "MIT"

# %% ../../nbs/utils/utils.ipynb 4
import sys
import os
import random as python_random
import logging
import shutil
try:
    import sh
    sh_imported = True
except ImportError:
    sh_imported = False
from pathlib import Path
import re
import inspect
import numpy as np
import copy
import warnings
import json

# dsblocks
import dsblocks.config.bt_defaults as dflt

# %% ../../nbs/utils/utils.ipynb 8
def json_load (path):
    with open (path, 'rt') as f: data = json.load (f)
    return data

def json_dump (data, path, mkdir=True, **kwargs):
    if mkdir: Path(path).parent.mkdir (parents=True, exist_ok=True)
    with open (path, 'wt') as f: json.dump (data, f, **kwargs)

# %% ../../nbs/utils/utils.ipynb 11
def make_reproducible (v1_seed=False, new_session=False):
    """
    Make results obtained from neural network model reproducible.

    This function should be run at the very beginning. The result
    of calling this is that the pipeline produces the exact same
    results as previous runs.
    """
    os.environ['CUDA_VISIBLE_DEVICES'] = ''
    os.environ['PYTHONHASHSEED'] = '0'
    os.environ['TF_DETERMINISTIC_OPS'] = '1'

    # The below is necessary for starting Numpy generated random numbers
    # in a well-defined initial state.
    np.random.seed(123)

    # The below is necessary for starting core Python generated random numbers
    # in a well-defined state.
    python_random.seed(123)

    # The below set_seed() will make random number generation
    # in the TensorFlow backend have a well-defined initial state.
    # For further details, see:
    # https://www.tensorflow.org/api_docs/python/tf/random/set_seed
    try:
        if v1_seed:
            tf.compat.v1.set_random_seed(1234)
        else:
            tf.random.set_seed(1234)
    except:
        print ('tensorflow needs to be installed in order to run make_reproducible()')

    # 5. Configure a new global `tensorflow` session
    if new_session:
        session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)
        sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)
        tf.compat.v1.keras.backend.set_session(sess)

# %% ../../nbs/utils/utils.ipynb 17
def get_logging_level (verbose):
    return logging.DEBUG if verbose == 2 else logging.INFO if verbose == 1 else logging.WARNING

# %% ../../nbs/utils/utils.ipynb 19
def delete_logger (name, path_results=dflt.path_logger_folder, filename=dflt.logger_filename):
    filename = f'{name}.log' if filename is None else filename
    if filename is not None and path_results is not None:
        path_to_log_file = f'{path_results}/{filename}'
        if os.path.exists (path_to_log_file):
            os.remove (path_to_log_file)

# %% ../../nbs/utils/utils.ipynb 21
def _set_file_handler (logger, path_results, filename, print_path, mode,
                       logging_level, just_message):
    os.makedirs(path_results, exist_ok=True)
    path_to_log_file = f'{path_results}/{filename}'
    #pdb.set_trace()
    if print_path: print (f'log written in {os.path.abspath(path_to_log_file)}')
    f_handler = logging.FileHandler (path_to_log_file, mode=mode)
    f_handler.setLevel(logging_level)
    if just_message:
        f_format = logging.Formatter('%(asctime)s - %(message)s')
    else:
        f_format = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s {%(filename)s:%(funcName)s:%(lineno)d} - %(message)s')
    f_handler.setFormatter(f_format)
    logger.addHandler(f_handler)

def set_logger (name, path_results=dflt.path_logger_folder, stdout=dflt.stdout_logger,
                mode=dflt.mode_logger, just_message = False, filename=dflt.logger_filename,
                null_file_name=dflt.logger_null_filename,
                null_name=dflt.null_name_logger, logging_level=logging.WARNING, verbose=None,
                verbose_out=None, print_path=False, second_path_results=None):
    """Set logger."""
    name= name if verbose is not None else null_name
    filename = null_file_name if verbose is None else f'{name}.log' if filename is None else filename
    logger = logging.getLogger(name)
    if verbose is not None:
        logging_level = get_logging_level (verbose)
    if verbose_out is not None:
        logging_level_out = get_logging_level (verbose_out)
    else:
        logging_level_out = logging_level
    logger.setLevel(logging_level)

    for hdlr in logger.handlers[:]:  # remove all old handlers
        hdlr.close()
        logger.removeHandler(hdlr)
    # Create handlers
    if stdout:
        c_handler = logging.StreamHandler()
        c_handler.setLevel(logging_level_out)
        c_format = logging.Formatter('%(message)s')
        c_handler.setFormatter(c_format)
        logger.addHandler(c_handler)
    else:
        logger.removeHandler(sys.stderr)

    if filename is not None and path_results is not None:
        _set_file_handler (logger, path_results, filename, print_path, mode, logging_level, just_message)
    if second_path_results is not None and (filename != null_file_name):
        _set_file_handler (logger, second_path_results, filename, print_path, mode, logging_level, just_message)
    #logger.propagate = 0
    logger.propagate = False

    return logger

# %% ../../nbs/utils/utils.ipynb 23
def set_empty_logger ():
    return set_logger ('no_logging', stdout=False, filename=None, verbose=0)

# %% ../../nbs/utils/utils.ipynb 25
def set_verbosity (name=None, logger=None, logging_level=logging.DEBUG, verbose=None, verbose_out=None):
    """Set logger."""
    if logger is None:
        assert name is not None, 'either logger or name must be not None'
        logger = logging.getLogger(name)
    if verbose is not None:
        logging_level = get_logging_level (verbose)
    if verbose_out is not None:
        logging_level_out = get_logging_level (verbose_out)
    else:
        logging_level_out = logging_level
    logger.setLevel(logging_level)

    for hdlr in logger.handlers[:]:  # remove all old handlers
        hdlr.setLevel(logging_level)

# %% ../../nbs/utils/utils.ipynb 29
def remove_previous_results (path_results=dflt.path_results):
    """Remove folder containing previous results, if exists."""
    if Path(path_results).exists():
        shutil.rmtree(path_results)

# %% ../../nbs/utils/utils.ipynb 31
def set_tf_loglevel(level):
    import tensorflow as tf
    if level >= logging.FATAL:
        os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
    if level >= logging.ERROR:
        os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
    if level >= logging.WARNING:
        os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'
    else:
        os.environ['TF_CPP_MIN_LOG_LEVEL'] = '0'
    logging.getLogger('tensorflow').setLevel(level)

    tf.get_logger().setLevel(level)

# %% ../../nbs/utils/utils.ipynb 35
def get_top_function (folder=None):
    folder = Path.cwd().name if folder is None else folder
    stack = inspect.stack()
    last_function_called = None
    for frame in stack:
        #print (frame.filename)
        if folder in frame.filename:
            #print (folder, frame.filename, last_function_called)
            last_function_called = copy.deepcopy(frame.function)
    #print (last_function_called)
    return last_function_called

# %% ../../nbs/utils/utils.ipynb 39
def get_calling_modules (folder=None, but=None, unique_modules=True, **kwargs):
    folder = Path.cwd().name if folder is None else folder
    stack = inspect.stack()
    selected_frames = {} if unique_modules else []
    for frame in stack:
        if folder in os.path.abspath(frame.filename) or folder=='all':
            if but is None or frame.function not in but:
                if unique_modules:
                    if frame.filename not in selected_frames:
                        selected_frames[frame.filename] = []
                    selected_frames[frame.filename].append (copy.copy(frame))
                else:
                    selected_frames.append (copy.copy(frame))

    if unique_modules:
        selected_frames2 = []
        for k in selected_frames:
            selected_frames2.append (selected_frames[k][-1])
        selected_frames = selected_frames2

    return selected_frames

# %% ../../nbs/utils/utils.ipynb 43
def add_commit_files (file_paths, copy_no_repo_files=False,
                      copy_no_repo_source_files=False,
                      out_of_repo_folder='out_of_repo_files',
                      out_of_repo_path=None,
                      message='new metadata files in {}',
                      result_string='last experiment', 
                      force_add=True,
                      create_new_branch=True):
    """
    Git adds files from not yet in current repo, or changed from last commit.

    If any of these two cases happen, it adds a new commit. If any of the files
    cannot be added, it either ignores the file or copies it to a folder in the
    repo whose relative path is the full absolute path of the original file.
    """
    use_git = sh_imported and Path ('.git').exists()
    if not use_git: 
        warnings.warn ('unable to add commit files')
        return
    git = sh.git.bake ()
    changed_files = False
    config_files = []
    for file_path in file_paths: 
        if not os.path.exists(file_path): continue
        try:
            if force_add: git.add ('-f', file_path)
            else: git.add (file_path)
            if len(git.status ('-s', '--', file_path))>0:
                changed_files = True
                if str(file_path).endswith ('root_metadata.json'):
                    config_files += [file_path]
        except Exception as e:
            if ((not str(file_path).endswith('.py') and copy_no_repo_files) or 
                (str(file_path).endswith('.py') and copy_no_repo_source_files)):
                if out_of_repo_path is None:
                    out_of_repo_path = Path (str(Path ('.').absolute() / out_of_repo_folder) + str(Path(file_path).parent.resolve()))
                else:
                    out_of_repo_path = Path (out_of_repo_path).resolve()
                out_of_repo_path2 = (out_of_repo_path if not str(file_path).endswith ('.py')
                                     else out_of_repo_path / 'source')
                out_of_repo_path2.mkdir (parents=True, exist_ok=True)
                shutil.copy (file_path, str(out_of_repo_path2))
                out_of_repo_file_path = out_of_repo_path2 / Path(file_path).name
                if force_add: git.add ('-f', str(out_of_repo_file_path))
                else: git.add (str(out_of_repo_file_path))
                if len(git.status ('-s', '--', str(out_of_repo_file_path)))>0:
                    changed_files = True
                    if str(out_of_repo_file_path).endswith ('root_metadata.json'):
                        config_files += [out_of_repo_file_path]
            else:
                print (f'ignored file: {file_path}, due to: {e}')
                
    if changed_files:
        current_branch = git('rev-parse', '--abbrev-ref', 'HEAD')
        current_hash = str(git ('rev-parse', 'HEAD'))
        current_hash = current_hash.split()[0]
        if create_new_branch and '__add_commit_files__' not in current_branch:
            git.checkout ('-b', f'{current_hash}__add_commit_files__')
        git_log = git.log ('-1')
        if ('new experiment' in git_log) or ('new metadata files in' in git_log):
            git.commit ('--amend', '-m', message.format (result_string))
        else:
            git.commit ('-m', message.format (result_string))
        new_hash = str(git ('rev-parse', 'HEAD'))
        for config_file in config_files:
            prev_metadata = json_load (config_file)
            if type(prev_metadata) is not list: prev_metadata = [prev_metadata] 
            prev_metadata[-1]['new_hash'] = new_hash
            json_dump (prev_metadata, config_file, indent=4)
            git.add (str(config_file))
        git.commit ('--amend', '-m', message.format (result_string))



# %% ../../nbs/utils/utils.ipynb 45
def check_message (message, expected):
    assert expected in str(message)

def check_new_files (git, expected_files):
    new_files_in_commit=list(git.diff ('HEAD..HEAD~1 --name-only'.split()))
    escapes = ''.join([chr(char) for char in range(1, 32)])
    translator = str.maketrans('', '', escapes)

    for expected_file in expected_files:
        good=False
        for i in range(len(new_files_in_commit)):
            x = new_files_in_commit[i].translate(translator)
            x = x.replace('[m ', '')
            x = x.replace('[m', '')
            good = expected_file in x
            if good:
                break
        assert good

    #n = len(expected_files)
    #assert len(new_files_in_commit)<=(n+1)
    #if len(new_files_in_commit)==(n+1):
    #    assert len(new_files_in_commit[n].split('/'))==1

# %% ../../nbs/utils/utils.ipynb 49
def add_out_of_repo_files (parameters, repo_path):
    tracked_files = parameters.get('additional_file_paths',[])
    parameters['additional_file_paths'] = tracked_files + [f'{repo_path}/config/call_stack.json',
                                                           f'{repo_path}/config/root_metadata.json']

# %% ../../nbs/utils/utils.ipynb 51
def compare_last_part (path, path_ref, return_last_part=False):
    number_parts = len(str(path_ref).split('/'))
    path = '/'.join(str(path).split('/')[-number_parts:])
    if return_last_part:
        return (path==path_ref, path)
    else:
        return path==path_ref

def check_last_part (path, path_ref):
    equal, path = compare_last_part (path, path_ref, return_last_part=True)
    assert equal, f'{path} != {path_ref}'

# %% ../../nbs/utils/utils.ipynb 55
def get_action ():
    from IPython.core.magic import register_cell_magic
    from IPython.core.magic_arguments import (argument, magic_arguments,
                                          parse_argstring)
    @register_cell_magic
    @magic_arguments()
    @argument('-r', '--run', default=1, type=int, help='Whether or not to run the code.')
    @argument('path', type=str, help='file path where code is written')
    def action (line, cell):
        args = parse_argstring(action, line)
        path = Path (args.path).resolve ()
        path.parent.mkdir (parents=True, exist_ok=True)
        with open (path, 'wt') as f: f.write (cell)
        if args.run:
            get_ipython().run_cell(cell)
    return action

# %% ../../nbs/utils/utils.ipynb 60
def get_norun ():
    from IPython.core.magic import register_cell_magic
    from IPython.core.magic_arguments import (argument, magic_arguments,
                                              parse_argstring)
    @register_cell_magic
    def norun (line, cell):
        pass
    return norun

# %% ../../nbs/utils/utils.ipynb 65
def get_existing_kwargs (func, kwargs, return_whole_kwargs=True):
    args = set(inspect.signature (func).parameters.keys())
    if 'kwargs' in args: 
        return kwargs if return_whole_kwargs else None
    else:
        return {k:kwargs[k] for k in args & kwargs.keys()}

# %% ../../nbs/utils/utils.ipynb 67
def call_with_existing_kwargs (func, kwargs, function_args, *args, get_function_args=False, **other_kwargs):
    if get_function_args: 
        function_args = (set () if func is None else set(inspect.signature (func).parameters.keys()))
        if 'kwargs' in function_args: function_args = None
    if function_args is not None:
        return func (*args, **{k:kwargs[k] for k in function_args & kwargs.keys()}, **other_kwargs)
    else:    
        return func (*args, **kwargs, **other_kwargs)

# %% ../../nbs/utils/utils.ipynb 69
def save_config (path_config_file='configs/config.json', dflt={}, **kwargs):
    from dsblocks.core.utils import Comparator

    path_config_file = Path (path_config_file)

    def mkdir_and_save (config, folder):
        path_config_file2 = path_config_file.parent / folder / path_config_file.name
        path_config_file2.parent.mkdir (parents=True, exist_ok=True)
        sorted_config = {k:config[k] for k in sorted(config)}
        json_dump(sorted_config, path_config_file2, indent=4, sort_keys=True)

    config = kwargs.copy()
    mkdir_and_save (config, 'complete')

    default_config = {k:dflt[k] for k in config if k in dflt}
    mkdir_and_save (default_config, 'default')

    # ******************
    c = Comparator ()
    diff_config = {k:config[k] for k in default_config if c.compare(config[k], default_config[k]) != ''}
    if config.get('path_models') is not None:
        diff_config.update (path_models=config['path_models'])
    mkdir_and_save (diff_config, 'diff')

    def_diff_config = {k:default_config[k] for k in diff_config}
    if 'path_models' in def_diff_config:
        def_diff_config.update (path_models=None)
    mkdir_and_save (def_diff_config, 'def_diff')

    # ******************
    not_in_def = set(list(config.keys())).difference (set(list(default_config.keys())))
    not_in_def = sorted(list(not_in_def))
    not_in_def_config = {k:config[k] for k in not_in_def}

    diff_and_not_in_def_config = {**diff_config, **not_in_def_config}
    mkdir_and_save (diff_and_not_in_def_config, 'diff_and_not_in_def')

    dict_config = {k:config[k] for k in not_in_def if isinstance(config[k], dict)}
    diff_and_dict_config = {**diff_config, **dict_config}
    mkdir_and_save (diff_and_dict_config, 'required')

    left_out_config = {k:config[k] for k in not_in_def if not isinstance(config[k], dict)}
    mkdir_and_save (left_out_config, 'left_out')

# %% ../../nbs/utils/utils.ipynb 75
def argnames(f, frame=False):
    "Names of arguments to function or frame `f`"
    code = getattr(f, 'f_code' if frame else '__code__')
    return code.co_varnames[:code.co_argcount+code.co_kwonlyargcount]

# %% ../../nbs/utils/utils.ipynb 76
def _store_attr(self, overwrite=False, error_if_present=False, ignore=set(), **attrs):
    stored = getattr(self, '__stored_args__', None)
    for n,v in attrs.items():
        if hasattr(self, n) and not overwrite:
            if (error_if_present and getattr(self, n) is not v and n not in ignore
                and not callable(getattr(self, n))):
                raise RuntimeError (f'field {n} already present in object from {self.__class__.__name__}')
            continue
        setattr(self, n, v)
        if stored is not None: stored[n] = v

# %% ../../nbs/utils/utils.ipynb 78
def store_attr(names=None, self=None, but='', store_args=None, **attrs):
    """Store params named in comma-separated `names` from calling context into attrs in `self`"""
    # Code copied almost unchanged from fastcore's store_attr
    fr = sys._getframe(1)
    args = argnames(fr, True)
    if self is not None and 'self' not in args: args = ('self', *args)
    if self is None: self = fr.f_locals[args[0]]
    if store_args is None: store_args = not hasattr(self,'__slots__')
    if store_args and not hasattr(self, '__stored_args__'): self.__stored_args__ = {}
    if names and isinstance(names,str): names = re.split(', *', names)
    ns = names if names is not None else getattr(self, '__slots__', args[1:])
    added = {n:fr.f_locals[n] for n in ns}
    attrs = {**attrs, **added}
    if isinstance(but,str): but = re.split(', *', but)
    attrs = {k:v for k,v in attrs.items() if k not in but}
    return _store_attr(self, **attrs)

# %% ../../nbs/utils/utils.ipynb 82
def get_specific_dict_param (self, **kwargs):
    if (hasattr(self, 'name') and
        kwargs.get(self.name) is not None and
        isinstance(kwargs[self.name], dict)):
        k = self.name
    elif (hasattr(self, 'class_name') and
        kwargs.get(self.class_name) is not None and
        isinstance(kwargs[self.class_name], dict)):
        k = self.class_name
    elif (hasattr(self, 'group') and
        kwargs.get(self.group) is not None and
        isinstance(kwargs[self.group], dict)):
        k = self.group
    elif (hasattr(self, 'hierarchy_level') and
        kwargs.get('levels') is not None and
        isinstance(kwargs['levels'], dict) and
        'until' in kwargs['levels'] and
        self.hierarchy_level <= kwargs['levels']['until']):
        k = 'levels'
    else:
        k = None

    return k

def obtain_class_specific_attrs (self, **kwargs):
    """Overwrites parameters in kwargs with those found in a dictionary of the same name
    given to this component.

    Checks if there is a parameter whose name is the name of the class or the name given
    to this component. In that case, it overwrites the parameters in kwargs with those
    found in that dictionary. The parameters in kwargs can be used as *global* parameters
    for multiple components, while parameters specific of one component can be set using
    a dictionary with the name of that component. See example below.
    """
    k = get_specific_dict_param (self, **kwargs)

    if k is not None:
        config = kwargs[k]
    else:
        config = {}

    return config

# %% ../../nbs/utils/utils.ipynb 84
def get_hierarchy_level (base_class=object):
    hierarchy_level=0
    try:
        stack = inspect.stack()
        last_type = None
        for frame_number in range(1, len(stack)):
            fr = sys._getframe(frame_number)
            fr_stack = stack[frame_number]
            if fr is not fr_stack[0]:
                raise RuntimeError ('fr is not fr_stack[0]')

            args = argnames(fr, True)
            if len(args) > 0:
                self = fr.f_locals[args[0]]
                if last_type is None:
                    last_type = type(self)
                if ((fr_stack.function == '__init__') and
                    isinstance(self, base_class) and
                    (type(self) != last_type) ):
                    hierarchy_level += 1
                    last_type = type(self)
    except Exception as e:
        warnings.warn (f'error {e} while calculating hierarchy level, returning 0')
    return hierarchy_level

# %% ../../nbs/utils/utils.ipynb 88
def replace_attr_and_store (names=None, but='', store_args=None,
                            recursive=True, base_class=object,
                            replace_generic_attr=True, overwrite=False,
                            error_if_present=False, ignore=set(), overwrite_name=True,
                            self=None, include_first=False, return_parent=False, 
                            init_names={'__init__'}, **attrs):
    """
    Replaces generic attributes and stores them into attrs in `self`.

    If kwargs contains an attribute called the same way as the class of
    self, all the keys in that dictionary are considered class-specific
    attributes whose value overwrites any attribute in kwargs of the same
    name.

    The function is called recursively in the hierarchy of parent classes,
    from the leaf to the root class, until it reaches an ascendant that
    is not an instance of `base_class`.

    Most of the implementation is taken from fastcore library, `store_attrs`
    function.
    """
    frame_number=1
    stack = inspect.stack()
    original_type = None
    input_attrs = attrs
    while True:
        fr = sys._getframe(frame_number)
        fr_stack = stack[frame_number]
        if fr is not fr_stack[0]:
            raise RuntimeError ('fr is not fr_stack[0]')

        args = argnames(fr, True)
        if recursive:
            if len(args) > 0:
                self = fr.f_locals[args[0]]
                if not isinstance(self, base_class):
                    if return_parent: 
                        return self
                    else: 
                        break
                if fr_stack.function not in init_names:
                    break
                if original_type is None:
                    original_type = type(self)

                if type(self) != original_type:
                    if return_parent: 
                        return self
                    else: 
                        break
            else:
                break
        else:
            if self is not None:
                if include_first:
                    args = [self] + list(args)
            elif len(args) > 0:
                self = fr.f_locals[args[0]]
            else:
                raise RuntimeError ('self not found')

        if store_args is None: store_args = not hasattr(self,'__slots__')
        if store_args and not hasattr(self, '__stored_args__'): self.__stored_args__ = {}
        if store_args and not hasattr(self, '__not_stored_args__'): self.__not_stored_args__ = set ()
        if names and isinstance(names,str): names = re.split(', *', names)
        #pdb.set_trace()
        ns = names if names is not None else getattr(self, '__slots__', args[1:])
        added = {n:fr.f_locals[n] for n in ns}
        attrs = {**input_attrs, **added}
        if replace_generic_attr and 'kwargs' in fr.f_locals:
            class_specific_attrs = obtain_class_specific_attrs (self, **fr.f_locals['kwargs'])
            attrs.update(class_specific_attrs)
        else:
            class_specific_attrs={}
        if isinstance(but,str): but = re.split(', *', but)
        attrs = {k:v for k,v in attrs.items() if k not in but}
        _store_attr(self, overwrite=overwrite, error_if_present=error_if_present,
                    ignore=ignore, **attrs)
        if overwrite_name and ('name' in class_specific_attrs
                               or 'class_name' in class_specific_attrs):
            new_attrs = {k:class_specific_attrs[k] for k in ['name', 'class_name']
                         if k in class_specific_attrs}
            _store_attr(self, overwrite=True, error_if_present=error_if_present,
                        ignore=ignore, **new_attrs)

        if store_args: 
            self.__not_stored_args__ |= set (but)
            if hasattr (self, 'name'): self.__not_stored_args__.add (self.name)
            if hasattr (self, 'class_name'): self.__not_stored_args__.add (self.class_name)
            
        if not recursive:
            break

        frame_number += 1
