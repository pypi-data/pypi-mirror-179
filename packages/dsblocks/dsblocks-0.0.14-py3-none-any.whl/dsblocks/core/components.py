# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/core/components.ipynb.

# %% auto 0
__all__ = ['DefaultDataConverter', 'PickleSaverComponent', 'Component', 'SamplingComponent', 'SklearnComponent',
           'NoSaverComponent', 'OneClassSklearnComponent', 'PandasComponent', 'io', 'pandas_io', 'component']

# %% ../../nbs/core/components.ipynb 3
__author__ = "Jaume Amores"
__copyright__ = "Copyright 2021, Johnson Controls"
__license__ = "MIT"

# %% ../../nbs/core/components.ipynb 4
from functools import partialmethod, partial
from typing import Optional, Union
import copy
import pickle
from pathlib import Path
import re
import inspect

from sklearn.utils import Bunch
import numpy as np
import pandas as pd
import pyarrow.parquet as pq
import pyarrow as pa
import joblib
from IPython.display import display

from fastcore.meta import delegates

# dsblocks
from .data_conversion import (DataConverter, NoConverter, PandasConverter,
                                              StandardConverter, GenericConverter,
                                              data_converter_factory)
from .utils import (save_csv,  save_parquet,  save_multi_index_parquet,
                                    save_keras_model,  save_csv_gz, read_csv, read_csv_gz)
from .utils import DataIO, SklearnIO, PandasIO, NoSaverIO
from .utils import data_io_factory
from .utils import ModelPlotter, Profiler, Comparator
from .utils import camel_to_snake, snake_to_camel
from .utils import get_ds_experiment_manager
from ..utils.utils import (set_logger, delete_logger, replace_attr_and_store,
                                  get_specific_dict_param, get_hierarchy_level, 
                                  call_with_existing_kwargs, get_existing_kwargs)
import dsblocks.config.bt_defaults as dflt

# %% ../../nbs/core/components.ipynb 5
DefaultDataConverter = eval (dflt.default_data_converter)

# %% ../../nbs/core/components.ipynb 8
class Component ():
    """
    Basic building block used in `DSBlocks` pipelines. 
    
    Provides functionality such as checkpointing, logging,
    profiling, data conversion, and more. All components in the pipeline inherit from `Component`. 
    
    Parameters
    ----------
    estimator: estimator object or function, optional.
        Typically, estimator is an object with methods such as as `predict`, 
        `transform` and `fit`, which are wrapped by the corresponding methods 
        in Component to create additional functionality such as data 
        conversion and checkpointing, logging, profiling, and others. Instead 
        of an estimator object, one can provide a function, which is used when 
        calling `predict`, `transform`, or `apply`. If neither an estimator 
        nor a function are provided, `Component` needs to be subclassed and 
        the subclass needs to implement at least an `_apply` method. 
        In general, the estimator object might be any object which
        we want to use in a given step of our pipeline, and not 
        necessarily an actual estimator or model.
    name: string or None, optional.
        Name of component. If not provided, it is inferred from one of the 
        following: `class_name` converted to camel case, name of the 
        estimator's class  converted to camel case, name of the provided 
        function, or name of the subclass inheriting from Component, 
        converted to camel case.
    class_name: string or None, optional.
        Class name given to component. If not provided, it is inferred from 
        one of the following: `name` converted to snake case, name of the 
        estimator's class, name of the provided function converted to 
        snake case, or name of the subclass inheriting from Component.
    suffix: string or None, optional.
        Suffix appended to the name of the component. This is useful for 
        having multiple components with the same sname, but each one with 
        a different suffix.
    group: string, optional.
        Name of the group to which this component belongs. Can be used for 
        assigning the same parameters to all the components of a given 
        group.
    root: Component object or None,
        Component object that is the root of the pipeline. Used for having 
        all the components in the pipeline store a reference to the root. 
        Useful for navigating across othercomponents of the pipeline
        when debugging, jumping to other branches of the pipeline or sibling
        components.
    data_converter: DataConverter or None, optional
        Converts incoming data to format expected by component, and convert
        outgoing result to format expected by caller.
    data_io: DataIO or None, optional
        Manages data serialization and deserialization for caching / 
        checkpointing  results.
    model_plotter: ModelPlotter or None, optional
        Helper object that stores and retrieves information to be shown about 
        this component, as part of a pipeline diagram.
    profiler: Profiler or None, optional
        Object that performs timing at different steps of each methods, 
        in order to analyze the computational cost of the different steps.
        See `Profiler` class in `core.utils` module.
    comparator: Comparator or None, optional
        Object that is able to compare two instances of this component.
        See `Comparator` class in `core.utils` module.
    tracker: Experiment tracker or None, optional
        Experiment tracker object that allows to store and retrieve 
        the Component parameters  and the results obtained with such parameters 
        for the different methods. 
    track_results: bool, optional
        Whether or not to use the aforementioned experiment tracker.
    apply: function or None, optional.
        Function to be used as `apply` method. Note that the `transform`,
        `predict` and `apply` methods are just aliases used for calling the
         same underlying function.
    fit_func_name: string, optional.
        Indicates the name of the method of the `estimator` object to be called 
        for fitting the estimator to given data. By default it is the 'fit' method.
        Only useful when the `estimator` object is given (see `estimator` argument 
        above).
    apply_func_name: string, optional.
        Name of the method of the `estimator` object to be called for *applying*
        (typically predicting / transforming) the estimator. When the estimator 
        object is an actual estimator, the apply function typically performs 
        some kind of inference (like the usual `predict` method does) or transforms 
        the data in a given way (like the usual `transform` method). However, more 
        in general, the estimator object can be any object which we want to use as 
        one of the steps of our pipeline, and not necessarily an actual estimator. 
        In this case, the apply_func_name is just the name of the method we want to 
        use for the mentioned step of the pipeline.
    fit_apply_func_name: string, optional.
        Indicates which method of the `estimator` object should be called 
        for fitting and then applying the estimator to given data. Only useful when 
        the `estimator` object is given (see `estimator` argument above).
    direct_apply: bool, optional.
        If True, additional functionalities (checkpointing, logging, profiling,
        etc.) are not performed by the `apply` method.
    direct_fit: bool, optional.
        If True, additional functionalities (checkpointing, logging, profiling,
        etc.) are not performed by the `fit` method.
    direct_fit_apply: bool, optional.
        If True,  additional functionalities (checkpointing, logging, profiling,
        etc.) are not performed by the `fit_apply` method.
    use_kwargs_direct: bool, optional.
        If True, the method to be called directly is first inspected to see which
        kwargs are valid for this method. If False, no kwargs are passed, only the 
        data.
    error_if_apply: bool, optional.
        If True, an exception is raised if the `apply` method is called.
    error_if_fit: bool, optional.
        If True, an exception is raised if the `fit` method is called.
    error_if_fit_apply: bool, optional.
        If True, an exception is raised if the `fit_apply` method is called.
    error_if_result_not_loaded: bool, optional.
        If True, the component expects to have a pre-computed available to be loaded, 
        and it raises an exception if that's not the case.
    error_if_estimator_not_loaded: bool, optional.
        If True, the component expects to have a pre-trained estimator available to be 
        loaded, and it raises an exception if that's not the case.
    compare_kwargs: bool, optional.
        If True, the component compares the remaining **kwargs against the ones used 
        by the current component and its callback objects. If any of kwargs is not used,
        it raises a warning or an exception (see next argument).
    error_if_kwargs_mismatch: bool, optional.
        If True, the component raises an exception if any of the kwargs is not used (see
        previous argument for further explanation)
    logger: Logger, optional.
        Logger to be used in the component. If None is provided, one is created using the 
        arguments below.
    verbose: int, optional.
        Verbosity of the logger. Only used when a new logger is created by the component. If
        an existing logger is given (see argument above), the verbosity of that logger is used
        instead. Currently, the only values of verbosity accepted are 0: warning or critical, 
        1: info, 2: debug.
    name_logger: string, optional.
        Name of the logger created by the component. If an existing logger is given (see argument 
        above), the name of that logger is used instead. 
    mode_logger: string, optional.
        Writing mode: 'w' = write and overwrite any previous content, 'a' = append new logs to 
        previously existing logs if the log file is already present. If an existing logger is 
        given (see argument above), the mode of that logger is used instead. 
    always_two_logs: bool, optional.
        Write logging messages to two different log files: one in the root folder (typically called
        `log`), common for all the pipelines, and another in the path_results folder, which is usually
        specific for the current pipeline (but common for all the components of the pipeline, so that
        all write to the same log file).
    but: string or list, optional.
        All the arguments passed at construction time are stored as attributes of the component, 
        except the ones indicated in `but`. 
    overwrite_field: bool, optional.
        If False, any argument passed in the constructor that is already an attribute stored in the 
        component, will not be overwritten, i.e., its original value will be preserved.        
    error_if_present: bool, optional.
        If True, an error is raised if the component already has an attribute stored with the same 
        name as the argument being passed in the constructor, and with a different value. Only used
        if overwrite_field is False.
    ignore: set, optional.
        An exception is not raised if the component already has an attribute stored with the same
        name as the argument passed in the constructor, but this name is part of the ignore set.
        Only used when overwrite_field is False and error_if_present is True.
    build_partial: bool, optional.
        Only used if either an estimator or an apply function is passed. In this case, 
        if build_partial is True, and if any of the kwargs is used by the `fit`, `apply` or 
        `fit_apply` methods of the estimator, or by the apply function passed, those functions 
        are converted to functools.partial, using the values of the parameters that are both 
        in kwargs and in the function's signature.
    """
    def __init__ (self,
                  # estimator object or function to be applied
                  estimator=None,
                  name: Optional[str]=None,
                  class_name: Optional[str]=None,
                  suffix: Optional[str]=None,
                  group: str=dflt.group,
                  root:Optional['Component']=None,
                  data_converter: Optional[DataConverter] = None,
                  data_io: Optional[DataIO] = None,
                  model_plotter: Optional[ModelPlotter] = None,
                  profiler: Optional[Profiler] = None,
                  comparator: Optional[Comparator] = None,
                  tracker=None,
                  track_results: bool = False,
                  apply=None,
                  build_partial: bool=dflt.build_partial, 
                  fit_func_name: str = 'fit',
                  apply_func_name: Optional[str] = None,
                  fit_apply_func_name:Optional[str]=None,
                  direct_apply: bool = False,
                  direct_fit: bool = False,
                  direct_fit_apply: bool = False,
                  use_kwargs_direct: bool = True,
                  error_if_apply: bool = False,
                  error_if_fit: bool = False,
                  error_if_fit_apply: bool = False,
                  error_if_result_not_loaded: bool = False,
                  error_if_estimator_not_loaded: bool = False,
                  compare_kwargs:bool=dflt.compare_kwargs,
                  error_if_kwargs_mismatch:bool=dflt.error_if_kwargs_mismatch,
                  logger: Optional['logging.Logger'] = None,
                  verbose: int = dflt.verbose,
                  name_logger:str = dflt.name_logger,
                  mode_logger:str = dflt.mode_logger,
                  always_two_logs: bool = dflt.always_two_logs,
                  but: Union[str, list] = '',
                  ignore:set = set(),
                  error_if_present: bool = dflt.error_if_present,
                  overwrite_field: bool = dflt.overwrite_field,
                  **kwargs):

        assert not isinstance(estimator, Component), 'estimator cannot be an instance of Component'
        if type(estimator).__name__=='function': 
            if apply is not None: 
                raise ValueError ('you cannot pass a function as estimator if you also pass `apply`')
            apply, estimator = estimator, None

        # name of current component, for logging and plotting purposes
        self._determine_component_name (name, estimator, class_name=class_name, suffix=suffix, apply=apply)

        # obtain hierarchy_level
        self.hierarchy_level = get_hierarchy_level (base_class=Component)

        # store __init__ attrs into `self`
        but = ', '.join (but) if isinstance(but, list) else but
        but = (but + ', ') if len(but)>0 else but
        but = but + 'ignore, but, overwrite_field, error_if_present, path_results, path_models, apply'
        if isinstance (ignore, str): ignore = set(re.split(', *', ignore))
        ignore.update ({'name', 'class_name', 'suffix', 'apply', 'data_converter'})
        replace_attr_and_store (base_class=Component, but=but,
                                error_if_present=error_if_present, overwrite=overwrite_field,
                                ignore=ignore)

        # obtain class-specific kwargs
        kwargs = self.obtain_config_params (**kwargs)

        # object that manages loading / saving
        if self.data_io is None:
            self.data_io = DataIO (component=self, **kwargs)
        else:
            if 'data_io' in kwargs:
                del kwargs['data_io']
            self.data_io = data_io_factory (self.data_io, component=self, **kwargs)
            self.data_io.set_parent (self)

        self.path_results = self.data_io.path_results
        self.path_models = self.data_io.path_models
        
        if self.logger is None:
            second_path_results = (self.path_results if (self.data_io.can_save_result () or 
                                                         self.data_io.can_save_model () or 
                                                         self.always_two_logs)
                                   else None)
            self.logger = set_logger (self.name_logger, second_path_results=second_path_results, 
                                      verbose=self.verbose, mode=self.mode_logger)

        # data converter
        if self.data_converter is None:
            # TODO: have DataConverter store a reference to component, and use the logger from that reference.
            self.data_converter = DefaultDataConverter (**kwargs)
        else:
            if 'data_converter' in kwargs:
                del kwargs['data_converter']
            self.data_converter = data_converter_factory (self.data_converter,
                                                          **kwargs)
            self.data_converter.set_parent (self)
        # plotting model component
        if self.model_plotter is None:
            self.model_plotter = ModelPlotter (component=self, **kwargs)
        else:
            self.model_plotter.set_component (self)

        # profiling computational cost
        if self.profiler is None:
            self.profiler = Profiler (self, **kwargs)

        # comparing results against other implementations of this component
        if self.comparator is None:
            self.comparator = Comparator (self, **kwargs)
        elif type(self.comparator) is type:
            self.comparator = self.comparator (self, **kwargs)
            
        if self.track_results and self.tracker is None:
            self.tracker = get_ds_experiment_manager (self, **kwargs)

        # determine and assign apply and fit functions
        self.assign_apply_and_fit_functions (apply=apply)
        
        # detect args used by apply and fit functions
        build_partial = build_partial and (estimator is not None or apply is not None)
        if build_partial:
            from dsblocks.core.compose import MultiComponent
            build_partial = not isinstance (self, MultiComponent)
        self.build_partials_and_determine_args (build_partial=build_partial, kwargs=kwargs)
        
        if compare_kwargs or error_if_kwargs_mismatch:
            self.compare_kwargs_against_actual_args (error_if_kwargs_mismatch=error_if_kwargs_mismatch, **kwargs)

    def _repr (self, class_type):
        if hasattr(self, 'class_name') and hasattr(self, 'name'):
            return f'{class_type} {self.class_name} (name={self.name})'
        else:
            return f'{class_type} {self.__class__.__name__}'
    def __repr__ (self):
        return self._repr ('Component')

    def reset_logger (self):
        delete_logger (self.name_logger)

    def get_specific_data_io_parameters (self, tag, **kwargs):
        suffix = f'_{tag}'
        n = len(suffix)
        self.__specific_attrs__ = set (k for k in kwargs 
                                       if k.endswith (suffix) and k[:-n] in DataIO.specific_params)
        return {k[:-n]:kwargs[k] for k in self.__specific_attrs__}
    
    def get_specific_tag_parameters (self, tag, **kwargs):
        suffix = f'_{tag}'
        n = len(suffix)
        self.__specific_attrs__ = set (k for k in kwargs if k.endswith (suffix))
        return {k[:-n]:kwargs[k] for k in self.__specific_attrs__}

    def obtain_config_params (self, tag=None, use_specific_tag_parameters=False, **kwargs):
        """Overwrites parameters in kwargs with those found in a dictionary of the same name
        as the component.

        Checks if there is a parameter whose name is the name of the class or the name given
        to this component. In that case, it overwrites the parameters in kwargs with those
        found in that dictionary. The parameters in kwargs can be used as *global* parameters
        for multiple components, while parameters specific of one component can be overwritten
        using a dictionary with the name of that component. See example below.
        """
        k = get_specific_dict_param (self, **kwargs)

        if k is not None:
            config = kwargs.copy()
            config.update (config[k])
        else:
            config = kwargs

        if tag is not None:
            if tag == '__name__': tag = self.name
            self.tag = tag
            if use_specific_tag_parameters: 
                config.update (self.get_specific_tag_parameters (tag, **kwargs))
            else:
                config.update (self.get_specific_data_io_parameters (tag, **kwargs))

        config.update(verbose=self.verbose,
                      logger=self.logger)

        return config

    def _determine_component_name (self, name: str, estimator, class_name:Optional[str]=None,
                                   suffix:Optional[str]=None, apply=None) -> None:
        """
        Determines an appropriate name for the component if not provided by input.

        If not provided, it is inferred from the name of the estimator's class, or
        the name of the custom class defining the componet.
        """
        if class_name is not None:
            self.class_name = class_name
        else:
            from dsblocks.core.compose import __all__ as all_mc
            self.class_name = self.__class__.__name__
            if self.class_name in set(__all__).union (all_mc):
                if estimator is not None: self.class_name = estimator.__class__.__name__
                elif apply is not None:
                    if hasattr (apply, '__name__'):
                        self.class_name = snake_to_camel (apply.__name__)
                    elif hasattr (apply, 'func') and apply.__class__.__name__ == 'partial':
                        self.class_name = snake_to_camel (apply.func.__name__)
                elif name is not None:
                    self.class_name = snake_to_camel (name)
                    

        if name is not None:
            self.name = name
        else:
            self.name = camel_to_snake (self.class_name)

        self.suffix = suffix
        if self.suffix is not None and self.suffix != '':
            self.name = f'{self.name}_{self.suffix}'

    def create_estimator (self, **kwargs):
        self.estimator = Bunch(**kwargs)

    def fit_like (self, *X, y=None, load=None, save=None, split=None,
                  func='_fit', validation_data=None, test_data=None,
                  sequential_fit_apply=False, fit_apply=False, converter_args={}, **kwargs):
        """
        Estimates the parameters of the component based on given data X and labels y.

        Uses the previously fitted parameters if they're found in disk and load
        is True.
        """
        if not fit_apply:
            self.profiler.start_timer ()
            profiler_method = 'fit'
        else:
            profiler_method = 'fit_apply'
            
        from dsblocks.core.compose import MultiComponent
            
        if self.error_if_fit and func=='_fit': raise RuntimeError (f'{self.name} should not call fit')
        if self.error_if_fit_apply and func=='_fit_apply':
            raise RuntimeError (f'{self.name} should not call fit_apply')
        X = self.data_converter.convert_single_tuple_for_fitting (X)
        X = X + (y, ) if y is not None else X

        if split is not None:
            self.original_split = self.data_io.split
            self.set_split (split)

        self.logger.info (f'fitting {self.name} (using {self.data_io.split} data)')

        previous_estimator = None
        if not isinstance (self, MultiComponent) and self.data_io.can_load_model (load):
            previous_estimator = self.data_io.load_estimator()

        already_computed = False
        if previous_estimator is not None or isinstance (self, MultiComponent):
            if func=='_fit':
                already_computed = True
            elif func=='_fit_apply':
                previous_result = None
                if self.data_io.can_load_result (load):
                    previous_result, already_computed = self.data_io.load_result (split=split, return_found=True)
                elif self.error_if_result_not_loaded:
                    raise RuntimeError ('result not loaded, and it should')
            else:
                raise ValueError (f'function {func} not valid')
        elif self.error_if_estimator_not_loaded and not isinstance (self, MultiComponent):
            raise RuntimeError ('estimator not loaded, and it should')
        
        if already_computed and isinstance (self, MultiComponent):
            if self.exist_all_estimators ():
                self.load_estimator ()
                previous_estimator = True
            else:
                already_computed = False
        
        if not already_computed:
            if func=='_fit_apply':
                X = self.data_converter.convert_before_fit_apply (
                    *X, sequential_fit_apply=sequential_fit_apply, **converter_args)
                X = self.data_converter.convert_no_tuple (X)
            elif func=='_fit':
                X = self.data_converter.convert_before_fitting (*X)
            else:
                raise ValueError (f'function {func} not valid')
            additional_data= self._add_validation_and_test (validation_data, test_data)
            if func=='_fit':
                self.profiler.start_no_overhead_timer ()
                call_with_existing_kwargs (self._fit, kwargs, self.fit_args, *X, **additional_data)
            elif func=='_fit_apply':
                assert self.fit_apply_func is not None, ('object must have _fit_apply method or one of '
                                                    'its aliases implemented when func="_fit_apply"')
                self.profiler.start_no_overhead_timer ()
                result = call_with_existing_kwargs (self.fit_apply_func, kwargs, self.fit_apply_args, *X, 
                                                    **additional_data)
            else:
                raise ValueError (f'function {func} not valid')
            self.profiler.finish_no_overhead_timer (method=profiler_method, split=self.data_io.split)
            if func=='_fit':
                _ = self.data_converter.convert_after_fitting (*X)
            elif func=='_fit_apply':
                result = self.data_converter.convert_after_fit_apply (
                    result, sequential_fit_apply=sequential_fit_apply, **converter_args)
                if self.data_io.can_save_result (save, split):
                    self.data_io.save_result (result, split=split)
            else:
                raise ValueError (f'function {func} not valid')
            if self.data_io.can_save_model (save):
                self.data_io.save_estimator ()
        else:
            if type(previous_estimator) is not bool: 
                self.set_estimator (previous_estimator)
            self.logger.info (f'loaded pre-trained {self.name}')
            if func=='_fit_apply':
                result = previous_result
                self.logger.info (f'loaded pre-computed result')

        if not (fit_apply and func == '_fit'):
            self.profiler.finish_timer (method=profiler_method, split=self.data_io.split)

        if split is not None:
            self.set_split (self.original_split)

        if func=='_fit':
            return self
        else:
            return result

    fit = partialmethod (fit_like, func='_fit')

    def fit_apply (self, *X, y=None, load=None, save=None, load_model=None, save_model=None,
                   load_result=None, save_result=None, func='_fit',
                   validation_data=None, test_data=None, sequential_fit_apply=False,
                   **kwargs):

        self.profiler.start_timer ()
        if self.error_if_fit_apply: raise RuntimeError (f'{self.name} should not call fit_apply')

        X = self.data_converter.convert_single_tuple_for_fitting (X)
        X = X + (y, ) if y is not None else X

        if self.fit_apply_func is not None:
            return self.fit_like (*X,
                                  load=load_model, save=save_model,
                                  func='_fit_apply', validation_data=validation_data,
                                  test_data=test_data, sequential_fit_apply=sequential_fit_apply,
                                  fit_apply=True, **kwargs)
        else:
            if self.direct_fit:
                kwargs_fit = get_existing_kwargs (self.fit, kwargs) if self.use_kwargs_direct else {}
            else:                
                kwargs_fit = dict(load=load_model, save=save_model,
                                  validation_data=validation_data,
                                  test_data=test_data,
                                  sequential_fit_apply=sequential_fit_apply,
                                  fit_apply=True, **kwargs)
                
            if self.direct_apply:
                kwargs_apply = get_existing_kwargs (self.apply, kwargs) if self.use_kwargs_direct else {}
            else:
                kwargs_apply = dict (load=load_result, save=save_result, fit_apply=True,
                                     sequential_fit_apply=sequential_fit_apply, **kwargs)
                               

            return self.fit (*X, **kwargs_fit).apply (*X, **kwargs_apply)

    def _add_validation_and_test (self, validation_data, test_data):
        additional_data = {}
        def add_data (data, split_name):
            if data is not None:
                if isinstance(data, tuple):
                    if len(data) > 0:
                        newX = data[0]
                    else:
                        self.logger.warning (f'empty {split_name}')
                        newX = None
                    if len(data) == 2:
                        newy = data[1]
                    elif len(data)==1:
                        newy = None
                    elif len(data)>2:
                        raise ValueError (f'{split_name} must have at most 2 elements')
                else:
                    newX = data
                    newy = None
                newX, newy = self.data_converter.convert_before_fitting (newX, newy)
                if newy is not None:
                    additional_data[split_name] = (newX, newy)
                else:
                    additional_data[split_name] = newX

        add_data (validation_data, 'validation_data')
        add_data (test_data, 'test_data')

        return additional_data

    # aliases
    fit_transform = fit_apply
    fit_predict = fit_apply

    def __call__ (self, *X, load=None, save=None, fit_apply=False, sequential_fit_apply=False, **kwargs):
        """
        Transforms the data X and returns the transformed data.

        Uses the previously transformed data if it's found in disk and load
        is True.
        """
        if not fit_apply: self.profiler.start_timer ()
        if self.direct_apply: return self.result_func (*X, **kwargs)
        if self.error_if_apply: raise RuntimeError (f'{self.name} should not call apply')
        assert self.result_func is not None, 'apply function not implemented'
        result = self._compute_result (X, self.result_func, load=load, save=save, fit_apply=fit_apply,
                                       sequential_fit_apply=sequential_fit_apply, **kwargs)
        return result

    def _assign_fit_func (self):
        self.fit_func = None
        self.estimator_fit_func = None
        if callable(getattr(self, '_fit', None)):
            self.fit_func = self._fit
        elif self.estimator is not None and callable(getattr(self.estimator, self.fit_func_name, None)):
            self.fit_func = getattr(self.estimator, self.fit_func_name)
            self.estimator_fit_func = self.fit_func_name

    def _assign_result_func (self):
        implemented = []
        self.result_func = None
        self.estimator_result_func = None
        if callable(getattr(self, '_apply', None)):
            self.result_func = self._apply
            implemented += [self.result_func]
        if callable(getattr(self, '_transform', None)):
            self.result_func = self._transform
            implemented += [self.result_func]
        if callable(getattr(self, '_predict', None)):
            self.result_func = self._predict
            implemented += [self.result_func]
        if len(implemented)==0:
            if self.apply_func_name is not None:
                if self.estimator is not None and callable(getattr(self.estimator, self.apply_func_name, None)):
                    self.result_func = getattr(self.estimator, self.apply_func_name)
                    self.estimator_result_func = self.apply_func_name
                    implemented += [self.result_func]
            else:
                if self.estimator is not None and callable(getattr(self.estimator, 'transform', None)):
                    self.result_func = self.estimator.transform
                    self.estimator_result_func = 'transform'
                    implemented += [self.result_func]
                if self.estimator is not None and callable(getattr(self.estimator, 'predict', None)):
                    self.result_func = self.estimator.predict
                    self.estimator_result_func = 'predict'
                    implemented += [self.result_func]
        if len(implemented) > 1:
            raise AttributeError (f'{self.class_name} must have only one of _transform, _apply, '
                                  f'or _predict methods implemented => found: {implemented}')

    def _assign_fit_apply_func (self):
        implemented = []
        self.fit_apply_func = None
        self.estimator_fit_apply_func = None
        if callable(getattr(self, '_fit_apply', None)):
            self.fit_apply_func = self._fit_apply
            implemented += [self.fit_apply_func]
        if callable(getattr(self, '_fit_transform', None)):
            self.fit_apply_func = self._fit_transform
            implemented += [self.fit_apply_func]
        if callable(getattr(self, '_fit_predict', None)):
            self.fit_apply_func = self._fit_predict
            implemented += [self.fit_apply_func]
        if len(implemented)==0:
            if self.fit_apply_func_name is not None:
                if self.estimator is not None and callable(getattr(self.estimator, self.fit_apply_func_name, 
                                                                   None)):
                    self.fit_apply_func = getattr(self.estimator, self.fit_apply_func_name)
                    self.estimator_fit_apply_func = self.fit_apply_func_name
                    implemented += [self.fit_apply_func]
            else:
                if self.estimator is not None and callable(getattr(self.estimator, 'fit_transform', None)):
                    self.fit_apply_func = self.estimator.fit_transform
                    self.estimator_fit_apply_func = 'fit_transform'
                    implemented += [self.fit_apply_func]
                if self.estimator is not None and callable(getattr(self.estimator, 'fit_predict', None)):
                    self.fit_apply_func = self.estimator.fit_predict
                    self.estimator_fit_apply_func = 'fit_predict'
                    implemented += [self.fit_apply_func]
        if len(implemented) > 1:
            raise AttributeError (f'{self.class_name} must have only one of fit_transform, fit_apply, '
                                  f'or fit_predict methods implemented => found: {implemented}')

    def assign_apply_and_fit_functions (self, apply=None):
        """Determine and assign apply and fit functions."""
        if apply is not None: self._apply = apply
        self._assign_result_func ()
        self._assign_fit_apply_func ()
        self._assign_fit_func ()
        self.is_model = True
        if self.fit_func is None:
            self._fit = self._fit_
            if self.fit_apply_func is None:
                self.is_model = False
        else:
            self._fit = self.fit_func
        if self.direct_apply:
            self.set_apply (self.result_func)
        if not self.is_model:
            self.fit = self._fit_
            # self.set_fit_apply (self.apply)
        else:
            if self.direct_fit:
                self.fit = self.fit_func
            if self.direct_fit_apply:
                self.set_fit_apply (self.fit_apply_func)
                
    def _determine_args (self, func):
        args = (set () if func is None else set(inspect.signature (func).parameters.keys()))
        return args if 'kwargs' not in args else None

    def _build_partial_from_kwargs (self, func_name, kwargs):
        function = getattr (self, func_name, None)
        if function is not None:
            parameters = get_existing_kwargs (function, kwargs)
            if parameters is not None: 
                setattr (self, func_name, partial (function, **parameters))
    
    def _build_partial_and_determine_args (self, func_name, build_partial, kwargs):
        if build_partial: self._build_partial_from_kwargs (func_name, kwargs)
        return self._determine_args (getattr (self, func_name))

    def build_partials_and_determine_args (self, build_partial=False, kwargs={}):
        self.apply_args = self._build_partial_and_determine_args ('result_func', build_partial, kwargs)
        self.fit_args = self._build_partial_and_determine_args ('fit_func', build_partial, kwargs) 
        self.fit_apply_args = self._build_partial_and_determine_args ('fit_apply_func', build_partial, kwargs)
                
    # aliases for transform method
    apply = __call__
    transform = __call__
    predict = partialmethod (__call__, converter_args=dict(new_columns=['prediction']))

    def _compute_result (self, X, result_func, load=None, save=None, split=None,
                         converter_args={}, fit_apply=False,
                         sequential_fit_apply=False, **kwargs):

        profiler_method = 'fit_apply' if fit_apply else 'apply'
        if split is not None:
            self.original_split = self.data_io.split
            self.set_split (split)

        self.logger.debug (f'applying {self.name} (on {self.data_io.split} data)')

        previous_result, already_computed = None, False
        if self.data_io.can_load_result (load):
            previous_result, already_computed = self.data_io.load_result (split=split, return_found=True)
        if not already_computed:
            if self.error_if_result_not_loaded:
                raise RuntimeError ('result not loaded, and it should')
            X = self.data_converter.convert_single_tuple_for_applying (X)
            X = self.data_converter.convert_before_applying (
                *X, fit_apply=fit_apply, sequential_fit_apply=sequential_fit_apply, **converter_args)
            X = self.data_converter.convert_no_tuple (X)
            X = self.data_converter.convert_single_tuple_for_result_func (X)
            self.profiler.start_no_overhead_timer ()
            result = call_with_existing_kwargs (result_func, kwargs, self.apply_args, *X)
            self.profiler.finish_no_overhead_timer (profiler_method, self.data_io.split)
            result = self.data_converter.convert_after_applying (
                result, fit_apply=fit_apply, sequential_fit_apply=sequential_fit_apply, **converter_args)
            if self.data_io.can_save_result (save, split):
                self.data_io.save_result (result, split=split)
        else:
            result = previous_result
            self.logger.info (f'loaded pre-computed result')

        self.profiler.finish_timer (profiler_method, self.data_io.split)
        if split is not None:
            self.set_split (self.original_split)

        return result

    def _fit_ (self, *X, **kwargs):
        return self

    def show_result_statistics (self, result=None, split=None) -> None:
        """
        Show statistics of transformed data.

        Parameters
        ----------
        result: DataFrame or other data structure or None, optional
            Transformed data whose statistics we show. If not provided, it is loaded
            from disk.
        training_data_flag: bool, optional
            If True, transformed training data is loaded, otherwise transformed test
            data is loaded.
        """
        if result is None:
            df = self.load_result(split=split)
        else:
            df = result

        if df is not None:
            display (self.name)
            if callable(getattr(df, 'describe', None)):
                display (df.describe())
            elif isinstance(df, np.ndarray) or isinstance(df, list):
                df = pd.DataFrame (df)
                display (df.describe())

    def remove_non_pickable_fields (self):
        pass
    
    def get_kwargs (self):
        used_kwargs = set(self.__stored_args__)
        used_kwargs |= self.__not_stored_args__
        if hasattr (self, '__specific_attrs__'):  used_kwargs |= self.__specific_attrs__
        for callback in self.callbacks:
            used_kwargs |= set(callback.__stored_args__)
            used_kwargs |= callback.__not_stored_args__
        return used_kwargs
    
    def compare_kwargs_against_actual_args (self, error_if_kwargs_mismatch=False, 
                                            used_kwargs=None, **kwargs):
        if used_kwargs is None: used_kwargs = set ()
        used_kwargs |= self.get_kwargs ()
        diff = set(kwargs).difference (used_kwargs)
        if len(diff) > 0:
            message = f'unrecognized arguments {diff}'
            if error_if_kwargs_mismatch: raise ValueError (message)
            else: self.logger.warning (message)


    # ********************************
    # exposing some data_io and data_converters methods
    # ********************************
    def load_estimator (self):
        estimator = self.data_io.load_estimator ()
        if estimator is not None:
            self.set_estimator (estimator)

    def load_result (self, split=None, path_results=None, result_file_name=None):
        return self.data_io.load_result (split=split, path_results=path_results,
                                         result_file_name=result_file_name)

    def assert_equal (self, item1, item2=None, split=None, raise_error=True, **kwargs):
        return self.comparator.assert_equal (item1, item2=item2, split=split,
                                             raise_error=raise_error, **kwargs)

    # ********************************
    # setters
    # ********************************
    def set_split (self, split):
        self.data_io.set_split (split)

    def set_save_splits (self, save_splits):
        self.data_io.set_save_splits (save_splits)

    def set_save_model (self, save_model):
        self.data_io.set_save_model (save_model)

    def set_load_model (self, load_model):
        self.data_io.set_load_model (load_model)

    def set_save_result (self, save_result):
        self.data_io.set_save_result (save_result)

    def set_load_result (self, load_result):
        self.data_io.set_load_result (load_result)

    def set_data_io (self, data_io, copy=False):
        self.data_io = copy.copy(data_io) if copy else data_io
        self.data_io.setup (self)

    def set_name (self, name):
        self._set_name (name)

    def _set_name (self, name, change_original=True):
        self.name = name
        self.data_io.set_file_names (name)
        if change_original: self.original_name = name

    def set_suffix (self, suffix):
        self.suffix = suffix
        if hasattr (self, 'original_name'):
            base_name = self.original_name
        else:
            base_name = self.name
            self.original_name = self.name
        suffix_string = f'_{suffix}' if (suffix is not None and suffix != '') else ''
        self._set_name (f'{base_name}{suffix_string}', change_original=False)

    def set_estimator (self, estimator):
        self.estimator = estimator
        if self.estimator_result_func is not None:
            self.result_func = getattr (self.estimator, self.estimator_result_func, None)
            assert callable (self.result_func)
        if self.estimator_fit_apply_func is not None:
            self.fit_apply_func = getattr (self.estimator, self.estimator_fit_apply_func, None)
            assert callable (self.fit_apply_func)
        if self.estimator_fit_func is not None:
            self.fit_func = getattr (self.estimator, self.estimator_fit_func, None)
            assert callable (self.fit_func)
            self._fit = self.fit_func
            assert self.is_model
        self.build_partials_and_determine_args ()

    def set_apply (self, result_func):
        self.apply = result_func
        self.__call__ = result_func
        self.transform = result_func
        self.predict = result_func
        self.build_partials_and_determine_args ()

    def set_fit_apply (self, fit_apply_func):
        self.fit_apply = fit_apply_func
        self.fit_transform = fit_apply_func
        self.fit_predict = fit_apply_func
        self.build_partials_and_determine_args ()
        
    # *****************************************************
    # *****************************************************
    def apply_and_track (self, *X, **kwargs):
        return self.tracker.apply (*X, **kwargs)
    def fit_and_track (self, *X, y=None, **kwargs):
        self.tracker.fit (*X, y=y, **kwargs)
    def fit_apply_and_track (self, *X, y=None, **kwargs):
        return self.tracker.fit_apply (*X, y=y, **kwargs)
    def set_track_results (self, track_results, **kwargs):
        self.track_results = track_results            
        if self.track_results and self.tracker is None:
            self.tracker = get_ds_experiment_manager (self, **kwargs)
        if not self.track_results:
            self.tracker = None

# %% ../../nbs/core/components.ipynb 71
#@delegates ()
class SamplingComponent (Component):
    """
    Component that makes use of labels in transform method.

    When calling the transform method, one of the columns of the received data
    is assumed to contain the ground-truth labels. This allows the transform
    method to modify the number of observations, changing the number of rows in
    the data and in the labels. See `PandasConverter` class in
    `dsblocks.core.data_conversion`.
    """
    def __init__ (self, estimator=None, apply_uses_labels=True, **kwargs):

        # the SamplingComponent over-rides the following parameters:
        super().__init__ (estimator=estimator, apply_uses_labels=apply_uses_labels,
                          **kwargs)

# %% ../../nbs/core/components.ipynb 75
#@delegates ()
class SklearnComponent (Component):
    """
    Component that saves estimator parameters in pickle format.

    Convenience subclass used when the results can be saved in
    pickle format. See `SklearnIO` class in `core.utils`.
    """
    def __init__ (self, estimator=None, data_io='SklearnIO', apply_uses_labels=False,
                  **kwargs):

        super().__init__ (estimator=estimator, data_io=data_io, apply_uses_labels=False,
                          **kwargs)

# alias
PickleSaverComponent = SklearnComponent

# %% ../../nbs/core/components.ipynb 79
#@delegates ()
class NoSaverComponent (Component):
    """Component that does not save any data."""
    def __init__ (self, estimator=None, data_io='NoSaverIO', **kwargs):

        super().__init__ (estimator=estimator, data_io=data_io, **kwargs)

# %% ../../nbs/core/components.ipynb 83
#@delegates ()
class OneClassSklearnComponent (SklearnComponent):
    """Component that uses only normal data (labelled with 0) for fitting parameters."""
    def __init__ (self, estimator=None, **kwargs):
        super().__init__ (estimator=estimator, **kwargs)

    def _fit (self, X, y=None):
        assert y is not None, 'y must be provided in OneClassSklearnComponent class'
        X = X[y==0]

        assert self.estimator is not None, 'estimator must be provided in OneClassSklearnComponent class'
        self.estimator.fit (X, y)

# %% ../../nbs/core/components.ipynb 89
#@delegates ()
class PandasComponent (Component):
    """
    Component that preserves the DataFrame format for incoming data and results.

    This component also writes results in parquet format, by default.
    See `PandasConverter` in `core.data_conversion` for details on the data
    conversion performed.
    """
    def __init__ (self, estimator=None, data_converter='PandasConverter', data_io='PandasIO',
                  **kwargs):
        super().__init__ (estimator=estimator, data_converter=data_converter, data_io=data_io,
                          **kwargs)

# %% ../../nbs/core/components.ipynb 94
def io (func):
    def wrapper_func(*args, **kwargs):
        component = Component (apply=func, **kwargs)
        result = component.apply (*args)
        return result
    return wrapper_func

# %% ../../nbs/core/components.ipynb 99
def pandas_io (func):
    def wrapper_func(*args, **kwargs):
        component = Component (apply=func, result_io='pandas', **kwargs)
        result = component.apply (*args)
        return result
    return wrapper_func

# %% ../../nbs/core/components.ipynb 104
def component (func):
    def wrapper_func(*args, **kwargs):
        return Component (apply=func, **kwargs)
    return wrapper_func
