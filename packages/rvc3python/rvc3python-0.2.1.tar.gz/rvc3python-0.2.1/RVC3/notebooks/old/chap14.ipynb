{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["------ standard imports ------ #"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import scipy as sp\n", "import matplotlib.pyplot as plt\n", "import cv2 as cv"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import ansitable\n", "ansitable.options(unicode=True)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from spatialmath import *\n", "from spatialmath.base import *\n", "BasePoseMatrix._color=False\n", "from roboticstoolbox import *"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from spatialmath.base import *\n", "import math\n", "from math import pi"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from machinevisiontoolbox import *\n", "from machinevisiontoolbox.base import *"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["np.set_printoptions(\n", "    linewidth=120, formatter={\n", "        'float': lambda x: f\"{0:8.4g}\" if abs(x) < 1e-10 else f\"{x:8.4g}\"})"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["np.random.seed(0)\n", "cv.setRNGSeed(0)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["------------------------------ #"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Point Feature Correspondence"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["view1 = Image.Read(\"eiffel-1.png\")\n", "view2 = Image.Read(\"eiffel-2.png\")\n", "hf = view1.Harris(nfeat=150)\n", "view1.disp(darken=True); hf.plot();\n", "sf = view1.SIFT().sort().filter(minscale=10)[:150]\n", "view1.disp(darken=True); sf.plot(filled=True, color=\"y\", alpha=0.3)\n", "hf[0].descriptor.shape\n", "hf[0].distance(hf[1], metric=\"ncc\")\n", "sf[0].descriptor.shape\n", "sf[0].distance(sf[1], metric=\"L2\")\n", "sf1 = view1.SIFT()\n", "sf2 = view2.SIFT()\n", "matches = sf1.match(sf2);\n", "len(matches)\n", "matches[:5].list()\n", "matches.subset(100).plot(color=\"yellow\")\n", "c = matches.correspondence();\n", "c[:, :5]\n", "plt.hist(matches.distance, cumulative=True, density=True);\n", "m = sf1.match(sf2, thresh=20);\n", "m = sf1.match(sf2, sort=True)[:10];\n", "m = sf1.match(sf2, ratio=0.8)\n", "m = sf1.match(sf2, crosscheck=True)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Geometry of Multiple Views"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["camera1 = CentralCamera(name=\"camera 1\", f=0.002, imagesize=1000,\n", "                        rho=10e-6, pose=SE3.Tx(-0.1)*SE3.Ry(0.4))\n", "camera2 = CentralCamera(name=\"camera 2\", f=0.002, imagesize=1000,\n", "                        rho=10e-6, pose=SE3.Tx(0.1)*SE3.Ry(-0.4))\n", "ax = plotvol3([-0.4, 0.6, -0.5, 0.5, -0.2, 1]);\n", "camera1.plot(ax=ax, scale=0.15, shape=\"camera\", frame=True, color=\"blue\");\n", "camera2.plot(ax=ax, scale=0.15, shape=\"camera\", frame=True, color=\"red\");\n", "P=[0.5, 0.1, 0.8];\n", "plot_sphere(0.03, P, color=\"blue\");\n", "p1 = camera1.plot_point(P)\n", "p2 = camera2.plot_point(P)\n", "e1 = camera1.plot_point(camera2.centre, \"kd\")\n", "e2 = camera2.plot_point(camera1.centre, \"kd\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The Fundamental Matrix"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["F = camera1.F(camera2)\n", "e2h(p2).T @ F @ e2h(p1)\n", "np.linalg.matrix_rank(F)\n", "e1h = sp.linalg.null_space(F);\n", "e1h.T\n", "e1 = h2e(e1h)\n", "e2h = sp.linalg.null_space(F.T);\n", "e2 = h2e(e2h)\n", "camera2.plot_epiline(F, p1, color=\"red\")\n", "camera1.plot_epiline(F.T, p2, color=\"red\");"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The Essential Matrix"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["E = camera1.E(F)\n", "T_1_2 = camera1.decomposeE(E);\n", "T_1_2.printline(orient=\"camera\")\n", "T_1_2_true = camera1.pose.inv() * camera2.pose;\n", "T_1_2_true.printline(orient=\"camera\")\n", "T_1_2_true.t / np.linalg.norm(T_1_2_true.t)\n", "Q = [0, 0, 10];\n", "camera1.project_point(Q).T\n", "for T in T_1_2:\n", " print(camera1.project_point(Q, pose=T).T)\n", "T = camera1.decomposeE(E, Q);\n", "T.printline(orient=\"camera\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Estimating the Fundamental Matrix from Real Image Data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["P = np.random.uniform(low=-1, high=1, size=(3, 10)) + np.c_[0, 0, 3].T;\n", "p1 = camera1.project_point(P);\n", "p2 = camera2.project_point(P);\n", "F, resid = CentralCamera.points2F(p1, p2)\n", "resid\n", "np.linalg.matrix_rank(F)\n", "camera2.plot_point(P);\n", "camera2.plot_epiline(F, p1, color=\"red\")\n", "p2[:,[5, 6]] = p2[:,[6, 5]];\n", "_, resid = CentralCamera.points2F(p1, p2);\n", "resid\n", "CentralCamera.epidist(F, p1[:, 0], p2[:,0])\n", "CentralCamera.epidist(F, p1[:, 5], p2[:,5])\n", "F, resid, inliers = CentralCamera.points2F(p1, p2, method=\"ransac\",\n", "                                           confidence=0.99, seed=0);\n", "resid\n", "inliers\n", "F, resid, inliers = CentralCamera.points2F(matches.p1, matches.p2,\n", "                                           method=\"ransac\", confidence=0.99);\n", "resid\n", "sum(inliers) / len(inliers)\n", "x = np.arange(11);\n", "y = 3 * x - 10;\n", "nbad = 4;\n", "np.random.seed(1)  # set the random number generator seed\n", "bad = np.random.choice(len(x), nbad, replace=False)\n", "y[bad] = y[bad] + np.random.rand(nbad) * 10\n", "import scipy as sp\n", "m, c, *_ = sp.stats.linregress(x, y)\n", "plt.plot(x, m * x + c, 'r--');\n", "sum([not inlier for inlier in inliers])\n", "F, resid = matches.estimate(CentralCamera.points2F, method=\"ransac\",\n", "                            confidence=0.99, seed=0);\n", "matches\n", "matches[:10].list()\n", "matches.inliers.subset(100).plot(color=\"g\");\n", "matches.outliers.subset(100).plot(color=\"red\")\n", "camera = CentralCamera();\n", "camera.disp(view1);\n", "camera.plot_epiline(F.T, matches.inliers.subset(20).p2, color=\"black\");\n", "epipole = h2e(sp.linalg.null_space(F))\n", "camera.plot_point(epipole, \"wd\");"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Planar Homography"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["T_grid = SE3.Tz(1) * SE3.Rx(0.1) * SE3.Ry(0.2);\n", "P = mkgrid(3, 1.0, pose=T_grid);\n", "p1 = camera1.plot_point(P, \"o\");\n", "p2 = camera2.plot_point(P, \"o\");\n", "H, resid = CentralCamera.points2H(p1, p2)\n", "H\n", "p2b = homtrans(H, p1);\n", "camera2.plot_point(p2b, \"+\");\n", "p1b = homtrans(np.linalg.inv(H), p1);\n", "Q = np.array([\n", "  [-0.2302,   -0.0545,    0.2537],\n", "  [ 0.3287,    0.4523,    0.6024],\n", "  [ 0.4000,    0.5000,    0.6000] ]);\n", "plotvol3([-1, 1, -1, 1, 0, 2]);\n", "plot_sphere(0.05, P, color=\"blue\");\n", "plot_sphere(0.05, Q, color=\"red\");\n", "camera1.plot(color=\"blue\", frame=True);\n", "camera2.plot(color=\"red\", frame=True);\n", "p1 = camera1.plot_point(np.hstack((P, Q)), \"o\");\n", "p2 = camera2.plot_point(np.hstack((P, Q)), \"o\");\n", "p2h = homtrans(H, p1);\n", "camera2.plot_point(p2h, \"+\");\n", "np.linalg.norm(homtrans(H, p1) - p2, axis=0)\n", "H, resid, inliers = CentralCamera.points2H(p1, p2, method=\"ransac\");\n", "resid\n", "inliers\n", "T, normals = camera1.decomposeH(H);\n", "T.printline(orient=\"camera\")\n", "(camera1.pose.inv() * camera2.pose).printline(orient=\"camera\")\n", "camera1.pose.inv() * T_grid\n", "normals[1].T\n", "walls_l = Image.Read(\"walls-l.png\", reduce=2);\n", "walls_r = Image.Read(\"walls-r.png\", reduce=2);\n", "sf_l = walls_l.SIFT();\n", "sf_r = walls_r.SIFT();\n", "matches = sf_l.match(sf_r);\n", "H, resid = matches.estimate(CentralCamera.points2H, confidence=0.9, seed=0)\n", "matches\n", "walls_l.disp();\n", "plot_point(matches.inliers.p1, \"r.\");\n", "not_plane = matches.outliers;"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Sparse Stereo"]}, {"cell_type": "markdown", "metadata": {}, "source": ["3D Triangulation"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["matches = sf_l.match(sf_r)\n", "F, resid = matches.estimate(CentralCamera.points2F, confidence=0.99, seed=0);\n", "matches = matches.inliers  # keep only the inliers\n", "camera = CentralCamera();\n", "camera.disp(walls_l);\n", "camera.plot_epiline(F.T, matches.subset(40).p2, \"yellow\");\n", "f = walls_l.metadata(\"FocalLength\")\n", "name = walls_l.metadata(\"Model\")\n", "camera = CentralCamera(name=name, imagesize=walls_l.shape,\n", "                       f=f/1000, rho=2*1.5e-6)\n", "E = camera.E(F)\n", "T_1_2 = camera.decomposeE(E, [0, 0, 10]);\n", "T_1_2.printline(orient=\"camera\")\n", "t = T_1_2.t;\n", "s = 0.3 / t[0]  # estimate of translation scale factor\n", "T_1_2.t = s * t  # scaled translation\n", "T_1_2.printline(orient=\"camera\")\n", "ray1 = camera.ray(matches[0].p1)\n", "ray2 = camera.ray(matches[0].p2, pose=T_1_2)\n", "P, e = ray1.closest_to_line(ray2);\n", "P\n", "e\n", "ray1 = camera.ray(matches.p1);\n", "ray2 = camera.ray(matches.p2, pose=T_1_2);\n", "len(ray1)\n", "P, e = ray1.closest_to_line(ray2);\n", "P.shape\n", "z = P[2, :];\n", "z.mean()\n", "np.median(e)\n", "e.max()\n", "plotvol3();\n", "plt.plot(P[0,:], P[1,:], P[2,:], '.', markersize=2);\n", "walls_pcd = PointCloud(P)\n", "walls_pcd.transform(SE3.Rx(pi));  # make y-axis upward\n", "walls_pcd = walls_pcd.remove_outlier(nb_points=10, radius=0.2)\n", "p1_reproj = camera.project_point(P[:, 0]);\n", "p2_reproj = camera.project_point(P[:, 0], pose=T_1_2);\n", "(p1_reproj - matches[0].p1).T\n", "(p2_reproj - matches[0].p2).T\n", "bundle = BundleAdjust(camera)\n", "view0 = bundle.add_view(SE3(), fixed=True);\n", "view1 = bundle.add_view(SE3.Tx(0.3));\n", "for (Pj, mj) in zip(P[:, ::4].T, matches[::4]):\n", "  landmark = bundle.add_landmark(Pj)             # add vertex\n", "  bundle.add_projection(view0, landmark, mj.p1)  # add edge\n", "  bundle.add_projection(view1, landmark, mj.p2)  # add edge\n", "bundle\n", "bundle.plot()\n", "x = bundle.getstate();\n", "x.shape\n", "x[6:12]\n", "x[12:15]\n", "bundle.errors(x)\n", "x_new, resid = bundle.optimize(x);\n", "bundle.setstate(x_new);\n", "bundle.views[1].pose.printline(orient=\"camera\")\n", "T_1_2.printline(orient=\"camera\")\n", "bundle.landmarks[0].P\n", "e = np.sqrt(bundle.getresidual());\n", "e.shape\n", "np.median(e, axis=1)\n", "np.max(e, axis=1)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Dense Stereo Matching"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["rocks_l = Image.Read(\"rocks2-l.png\", reduce=2)\n", "rocks_r = Image.Read(\"rocks2-r.png\", reduce=2)\n", "rocks_l.stdisp(rocks_r)\n", "disparity, *_ = rocks_l.stereo_simple(rocks_r, hw=3, drange=[40, 90]);\n", "disparity.disp(colorbar=True);\n", "disparity, similarity, DSI = rocks_l.stereo_simple(rocks_r, hw=3, drange=[40, 90])\n", "DSI.shape\n", "np.argmax(DSI, axis=2);\n", "similarity_values = np.max(DSI, axis=2);\n", "plt.plot(DSI[439, 138, :], \"o-\");"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Peak Refinement"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["disparity_refined, A = Image.DSI_refine(DSI)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Stereo Failure Modes"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Multiple peaks"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Weak matching"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["similarity.disp();\n", "similarity.choose(\"blue\", similarity < 0.6).disp();\n", "plt.hist(similarity.view1d(), 100, (0, 1), cumulative=True, density=True);"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Broad peak"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Quantifying Failure Modes"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["status = np.ones(disparity.shape);\n", "U, V = disparity.meshgrid()\n", "status[np.isnan(disparity.image)] = 5   # no similarity computed\n", "status[U <= 90] = 2                     # no overlap\n", "status[similarity.image < 0.6] = 3      # weak match\n", "status[A.image >= -0.1] = 4             # broad peak\n", "plt.imshow(status);\n", "(status == 1).sum() / status.size * 100\n", "disparity_valid = disparity.choose(0, status!=1)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Slicing the DSI"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["Image(DSI[100, :, :].T).disp();"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Summary"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Advanced Stereo Matching"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["disparity_BM = rocks_l.stereo_BM(rocks_l, hw=3, drange=[40, 90], speckle=(200, 2))\n", "disparity_BM.disp();\n", "rocks_l.stereo_SGBM(rocks_l, hw=3, drange=[40, 90], speckle=(200, 2)).disp();"]}, {"cell_type": "markdown", "metadata": {}, "source": ["3D Reconstruction"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["di = disparity_BM.image * 2 + 274;\n", "U, V = disparity_BM.meshgrid();\n", "u0, v0 = disparity.centre;\n", "f = 3740;   # pixels, according to Middlebury website\n", "b = 0.160;  # m, according to Middlebury website\n", "X = b * (U - u0) / di; Y = b * (V - v0) / di; Z = f * b / di;\n", "cam = CentralCamera(f=f, imagesize=rocks_l.shape);\n", "pcd = PointCloud(Z, image=rocks_l, camera=cam, depth_trunc=1.9)\n", "pcd *= SE3.Rx(pi);  # make y-axis upward"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Image Rectification"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["walls_l = Image.Read('walls-l.png', reduce=2)\n", "walls_r = Image.Read('walls-r.png', reduce=2)\n", "sf_l = walls_l.SIFT()\n", "sf_r = walls_r.SIFT()\n", "matches = sf_l.match(sf_r);\n", "F, resid = matches.estimate(CentralCamera.points2F,\n", "                            method=\"ransac\", confidence=0.95);\n", "H_l, H_r = walls_l.rectify_homographies(matches, F)\n", "walls_l_rect = walls_l.warp_perspective(H_l)\n", "walls_r_rect = walls_r.warp_perspective(H_r)\n", "walls_l_rect.stdisp(walls_r_rect)\n", "walls_l_rect.stereo_SGBM(walls_r_rect, hw=7, drange=[180, 530], speckle=(50, 2)).disp();"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Anaglyphs"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["walls_l.anaglyph(walls_r, \"rc\").disp();"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Other Depth Sensing Technologies"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Depth from Structured Light"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Depth from Time-Of-Flight"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Point Clouds"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["bunny_pcd = PointCloud.Read('data/bunny.ply')\n", "bunny_pcd.disp(block=False)\n", "pcd = bunny_pcd.voxel_grid(voxel_size=0.01).disp()\n", "pcd = bunny_pcd.downsample_voxel(voxel_size=0.01)\n", "pcd.normals(radius=0.1, max_nn=30)\n", "pcd.disp(block=False)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Fitting a Plane"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["pcd = walls_pcd\n", "plane, plane_pcd, pcd = pcd.segment_plane(distance_threshold=0.05, seed=0)\n", "plane\n", "plane_pcd\n", "plane, plane_pcd, pcd = pcd.segment_plane(distance_threshold=0.05, seed=0)\n", "plane"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Matching Two Sets of Points"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model = bunny_pcd.downsample_random(0.1, seed=0)\n", "data = SE3.Trans(0.3, 0.4, 0.5) * SE3.Rz(50, unit=\"deg\") * bunny_pcd.downsample_random(0.05, seed=-1);\n", "model.paint([0, 0, 1])  # blue\n", "data.paint([1, 0, 0])   # red\n", "(model + data).disp(block=False)\n", "T, status = model.ICP(data, max_correspondence_distance=1,\n", "                max_iteration=2000, relative_fitness=0, relative_rmse=0)\n", "T.printline()\n", "(model + T.inv() * data).disp(block=False)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Applications"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Perspective Correction"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["notredame = Image.Read(\"notre-dame.png\");\n", "notredame.disp();\n", "p1 = np.array([\n", "        [ 44.1364,   94.0065,  537.8506,  611.8247],\n", "        [377.0654,  152.7850,  163.4019,  366.4486]]);\n", "plot_polygon(p1, filled=True, color=\"y\", alpha=0.4, linewidth=2);\n", "plot_point(p1, \"yo\");\n", "mn = p1.min(axis=1);\n", "mx = p1.max(axis=1);\n", "p2 = np.array([[mn[0], mn[0], mx[0], mx[0]], [mx[1], mn[1], mn[1], mx[1]]]);\n", "plot_polygon(p2, \"k--\", close=True, linewidth=2);\n", "H, _ = CentralCamera.points2H(p1, p2, method=\"leastsquares\")\n", "H\n", "notredame.warp_perspective(H).disp();\n", "f = notredame.metadata(\"FocalLength\")\n", "cam = CentralCamera(imagesize=notredame.shape, f=f/1000, sensorsize=[7.18e-3, 5.32e-3])\n", "pose, normals = cam.decomposeH(H)\n", "pose.printline(orient=\"camera\")\n", "normals[0].T"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Image Mosaicing"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["images = ImageCollection(\"mosaic/aerial2-*.png\", mono=True);\n", "composite = Image.Zeros(2_000, 2_000)\n", "composite.paste(images[0], (0, 0));\n", "next_image = images[1]\n", "sf_c = composite.SIFT()\n", "sf_next= next_image.SIFT()\n", "match = sf_c.match(sf_next);\n", "H, _ = match.estimate(CentralCamera.points2H, \"ransac\", confidence=0.99);\n", "H\n", "tile, topleft, corners = next_image.warp_perspective(H, inverse=True, tile=True)\n", "composite.paste(tile, topleft, method=\"blend\");"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Visual Odometry"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["left = ZipArchive(\"bridge-l.zip\", filter=\"*.pgm\", mono=True, dtype=\"uint8\",\n", "                  maxintval=4095, roi=[20, 750, 20, 480]);\n", "len(left)\n", "for image in images:\n", "  image.disp(reuse=True, block=0.05)\n", "right = ZipArchive(\"bridge-r.zip\", mono=True, dtype=\"uint8\",\n", "                   maxintval=4095, roi=[20, 750, 20, 480]);\n", "ts = np.loadtxt(left.open(\"timestamps.dat\"));\n", "plt.plot(np.diff(ts));"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Wrapping Up"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Further Reading"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Resources"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Exercises"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}